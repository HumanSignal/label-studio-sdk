# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..core.datetime_utils import serialize_datetime
from .s_3_import_storage_meta import S3ImportStorageMeta
from .s_3_import_storage_status import S3ImportStorageStatus

try:
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore


class S3ImportStorage(pydantic.BaseModel):
    id: typing.Optional[int]
    type: typing.Optional[str]
    synchronizable: typing.Optional[bool]
    presign: typing.Optional[bool]
    last_sync: typing.Optional[dt.datetime] = pydantic.Field(description="Last sync finished time")
    last_sync_count: typing.Optional[int] = pydantic.Field(description="Count of tasks synced last time")
    last_sync_job: typing.Optional[str] = pydantic.Field(description="Last sync job ID")
    status: typing.Optional[S3ImportStorageStatus]
    traceback: typing.Optional[str] = pydantic.Field(description="Traceback report for the last failed sync")
    meta: typing.Optional[S3ImportStorageMeta] = pydantic.Field(
        description="Meta and debug information about storage processes"
    )
    title: typing.Optional[str] = pydantic.Field(description="Cloud storage title")
    description: typing.Optional[str] = pydantic.Field(description="Cloud storage description")
    created_at: typing.Optional[dt.datetime] = pydantic.Field(description="Creation time")
    bucket: typing.Optional[str] = pydantic.Field(description="S3 bucket name")
    prefix: typing.Optional[str] = pydantic.Field(description="S3 bucket prefix")
    regex_filter: typing.Optional[str] = pydantic.Field(description="Cloud storage regex for filtering objects")
    use_blob_urls: typing.Optional[bool] = pydantic.Field(description="Interpret objects as BLOBs and generate URLs")
    aws_access_key_id: typing.Optional[str] = pydantic.Field(description="AWS_ACCESS_KEY_ID")
    aws_secret_access_key: typing.Optional[str] = pydantic.Field(description="AWS_SECRET_ACCESS_KEY")
    aws_session_token: typing.Optional[str] = pydantic.Field(description="AWS_SESSION_TOKEN")
    aws_sse_kms_key_id: typing.Optional[str] = pydantic.Field(description="AWS SSE KMS Key ID")
    region_name: typing.Optional[str] = pydantic.Field(description="AWS Region")
    s_3_endpoint: typing.Optional[str] = pydantic.Field(alias="s3_endpoint", description="S3 Endpoint")
    presign_ttl: typing.Optional[int] = pydantic.Field(description="Presigned URLs TTL (in minutes)")
    recursive_scan: typing.Optional[bool] = pydantic.Field(description="Perform recursive scan over the bucket content")
    project: int = pydantic.Field(description="A unique integer value identifying this project.")

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().dict(**kwargs_with_defaults)

    class Config:
        frozen = True
        smart_union = True
        allow_population_by_field_name = True
        json_encoders = {dt.datetime: serialize_datetime}
