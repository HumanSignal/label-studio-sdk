# This file was auto-generated by Fern from our API Definition.

import typing

from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.request_options import RequestOptions
from .raw_client import AsyncRawStatsClient, RawStatsClient
from .types.agreement_annotator_stats_response import AgreementAnnotatorStatsResponse
from .types.agreement_annotators_stats_response import AgreementAnnotatorsStatsResponse
from .types.data_filters_stats_response import DataFiltersStatsResponse
from .types.finished_tasks_stats_response import FinishedTasksStatsResponse
from .types.iaa_stats_response import IaaStatsResponse
from .types.lead_time_stats_response import LeadTimeStatsResponse
from .types.model_version_annotator_agreement_stats_response import ModelVersionAnnotatorAgreementStatsResponse
from .types.model_version_ground_truth_agreement_stats_response import ModelVersionGroundTruthAgreementStatsResponse
from .types.model_version_prediction_agreement_stats_response import ModelVersionPredictionAgreementStatsResponse
from .types.total_agreement_stats_response import TotalAgreementStatsResponse
from .types.user_ground_truth_agreement_stats_response import UserGroundTruthAgreementStatsResponse
from .types.user_prediction_agreement_stats_response import UserPredictionAgreementStatsResponse
from .types.user_review_score_stats_response import UserReviewScoreStatsResponse
from .types.users_ground_truth_agreement_stats_response import UsersGroundTruthAgreementStatsResponse
from .types.users_prediction_agreement_stats_response import UsersPredictionAgreementStatsResponse
from .types.users_review_score_stats_response import UsersReviewScoreStatsResponse


class StatsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawStatsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawStatsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawStatsClient
        """
        return self._raw_client

    def model_version_annotator_agreement(
        self, id: int, model_version: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ModelVersionAnnotatorAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and all annotators in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionAnnotatorAgreementStatsResponse
            Model-version overall agreement vs annotators

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.model_version_annotator_agreement(
            id=1,
            model_version="model_version",
        )
        """
        _response = self._raw_client.model_version_annotator_agreement(
            id, model_version, request_options=request_options
        )
        return _response.data

    def model_version_ground_truth_agreement(
        self,
        id: int,
        model_version: str,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ModelVersionGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and ground truth annotations in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionGroundTruthAgreementStatsResponse
            Model-version ground truth agreement

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.model_version_ground_truth_agreement(
            id=1,
            model_version="model_version",
        )
        """
        _response = self._raw_client.model_version_ground_truth_agreement(
            id, model_version, per_label=per_label, request_options=request_options
        )
        return _response.data

    def model_version_prediction_agreement(
        self,
        id: int,
        model_version: str,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ModelVersionPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and all other model versions in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionPredictionAgreementStatsResponse
            Model-version prediction agreement

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.model_version_prediction_agreement(
            id=1,
            model_version="model_version",
        )
        """
        _response = self._raw_client.model_version_prediction_agreement(
            id, model_version, per_label=per_label, request_options=request_options
        )
        return _response.data

    def iaa(
        self,
        id: int,
        *,
        expand: typing.Optional[str] = None,
        per_label: typing.Optional[bool] = None,
        std: typing.Optional[bool] = None,
        task: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> IaaStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get Inter-Annotator Agreement (IAA) matrix for a project, showing agreement between all annotators.

        Parameters
        ----------
        id : int

        expand : typing.Optional[str]
            Comma-separated list of fields to expand

        per_label : typing.Optional[bool]
            Calculate IAA per label

        std : typing.Optional[bool]
            Include standard deviation in results

        task : typing.Optional[str]
            Comma-separated list of task IDs to filter by

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        IaaStatsResponse
            Inter-Annotator Agreement matrix

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.iaa(
            id=1,
        )
        """
        _response = self._raw_client.iaa(
            id, expand=expand, per_label=per_label, std=std, task=task, request_options=request_options
        )
        return _response.data

    def users_ground_truth_agreement(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get ground truth agreement statistics for multiple users within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of user IDs to get ground truth agreement for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersGroundTruthAgreementStatsResponse
            Ground truth agreement statistics for multiple users

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.users_ground_truth_agreement(
            id=1,
            ids="ids",
        )
        """
        _response = self._raw_client.users_ground_truth_agreement(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    def agreement_annotator(
        self, id: int, user_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AgreementAnnotatorStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement statistics for a specific annotator within a project.

        Parameters
        ----------
        id : int

        user_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgreementAnnotatorStatsResponse
            Individual annotator agreement statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.agreement_annotator(
            id=1,
            user_id=1,
        )
        """
        _response = self._raw_client.agreement_annotator(id, user_id, request_options=request_options)
        return _response.data

    def agreement_annotators(
        self, id: int, *, ids: str, request_options: typing.Optional[RequestOptions] = None
    ) -> AgreementAnnotatorsStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement statistics for multiple annotators within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get agreement scores for

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgreementAnnotatorsStatsResponse
            Multiple annotator agreement statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.agreement_annotators(
            id=1,
            ids="ids",
        )
        """
        _response = self._raw_client.agreement_annotators(id, ids=ids, request_options=request_options)
        return _response.data

    def data_filters(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> DataFiltersStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get statistics about user data filters and their usage within a project.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DataFiltersStatsResponse
            User data filter statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.data_filters(
            id=1,
        )
        """
        _response = self._raw_client.data_filters(id, request_options=request_options)
        return _response.data

    def finished_tasks(
        self, id: int, *, user_pk: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> FinishedTasksStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get statistics about finished tasks for a project.

        Parameters
        ----------
        id : int

        user_pk : typing.Optional[int]
            User ID to filter statistics by (optional)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FinishedTasksStatsResponse
            Finished tasks statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.finished_tasks(
            id=1,
        )
        """
        _response = self._raw_client.finished_tasks(id, user_pk=user_pk, request_options=request_options)
        return _response.data

    def lead_time(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> LeadTimeStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get lead time statistics across the project, including average annotation time.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LeadTimeStatsResponse
            Lead time statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.lead_time(
            id=1,
        )
        """
        _response = self._raw_client.lead_time(id, request_options=request_options)
        return _response.data

    def total_agreement(
        self,
        id: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TotalAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Overall or per-label total agreement across the project.

        NOTE: due to an open issue in Fern, SDK clients will raise ApiError upon handling a 204 response. As a workaround, wrap call to this function in a try-except block.

        Parameters
        ----------
        id : int

        per_label : typing.Optional[bool]
            Return agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TotalAgreementStatsResponse
            Total agreement

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.total_agreement(
            id=1,
        )
        """
        _response = self._raw_client.total_agreement(id, per_label=per_label, request_options=request_options)
        return _response.data

    def update_stats(
        self,
        id: int,
        *,
        stat_type: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, typing.Any]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Start stats recalculation for given project

        Parameters
        ----------
        id : int

        stat_type : typing.Optional[str]
            Stat type to recalculate. Possible values: label, stats

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, typing.Any]
            Successful response returns job id

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.update_stats(
            id=1,
        )
        """
        _response = self._raw_client.update_stats(id, stat_type=stat_type, request_options=request_options)
        return _response.data

    def users_prediction_agreement(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get prediction agreement statistics for multiple annotators within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get agreement scores for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersPredictionAgreementStatsResponse
            Prediction agreement statistics for multiple annotators

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.users_prediction_agreement(
            id=1,
            ids="ids",
        )
        """
        _response = self._raw_client.users_prediction_agreement(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    def users_review_score(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersReviewScoreStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get review score and performance score statistics for multiple annotators within a project. Only allowed for accounts with reviewing features enabled.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get review scores for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersReviewScoreStatsResponse
            Review scores and performance scores for multiple annotators

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.users_review_score(
            id=1,
            ids="ids",
        )
        """
        _response = self._raw_client.users_review_score(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    def user_prediction_agreement(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get prediction agreement statistics for a specific user within a project.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserPredictionAgreementStatsResponse
            Individual user prediction agreement statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.user_prediction_agreement(
            id=1,
            user_pk=1,
        )
        """
        _response = self._raw_client.user_prediction_agreement(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data

    def user_review_score(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserReviewScoreStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get review score statistics for a specific user within a project. Only allowed for accounts with reviewing features enabled.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserReviewScoreStatsResponse
            Individual user review score statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.user_review_score(
            id=1,
            user_pk=1,
        )
        """
        _response = self._raw_client.user_review_score(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data

    def user_ground_truth_agreement(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get ground truth agreement statistics for a specific user within a project.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserGroundTruthAgreementStatsResponse
            Individual user ground truth agreement statistics

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.projects.stats.user_ground_truth_agreement(
            id=1,
            user_pk=1,
        )
        """
        _response = self._raw_client.user_ground_truth_agreement(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data


class AsyncStatsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawStatsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawStatsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawStatsClient
        """
        return self._raw_client

    async def model_version_annotator_agreement(
        self, id: int, model_version: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ModelVersionAnnotatorAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and all annotators in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionAnnotatorAgreementStatsResponse
            Model-version overall agreement vs annotators

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.model_version_annotator_agreement(
                id=1,
                model_version="model_version",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.model_version_annotator_agreement(
            id, model_version, request_options=request_options
        )
        return _response.data

    async def model_version_ground_truth_agreement(
        self,
        id: int,
        model_version: str,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ModelVersionGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and ground truth annotations in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionGroundTruthAgreementStatsResponse
            Model-version ground truth agreement

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.model_version_ground_truth_agreement(
                id=1,
                model_version="model_version",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.model_version_ground_truth_agreement(
            id, model_version, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def model_version_prediction_agreement(
        self,
        id: int,
        model_version: str,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ModelVersionPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement between a given model version and all other model versions in the project for overlapping tasks.

        Parameters
        ----------
        id : int

        model_version : str

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelVersionPredictionAgreementStatsResponse
            Model-version prediction agreement

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.model_version_prediction_agreement(
                id=1,
                model_version="model_version",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.model_version_prediction_agreement(
            id, model_version, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def iaa(
        self,
        id: int,
        *,
        expand: typing.Optional[str] = None,
        per_label: typing.Optional[bool] = None,
        std: typing.Optional[bool] = None,
        task: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> IaaStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get Inter-Annotator Agreement (IAA) matrix for a project, showing agreement between all annotators.

        Parameters
        ----------
        id : int

        expand : typing.Optional[str]
            Comma-separated list of fields to expand

        per_label : typing.Optional[bool]
            Calculate IAA per label

        std : typing.Optional[bool]
            Include standard deviation in results

        task : typing.Optional[str]
            Comma-separated list of task IDs to filter by

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        IaaStatsResponse
            Inter-Annotator Agreement matrix

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.iaa(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.iaa(
            id, expand=expand, per_label=per_label, std=std, task=task, request_options=request_options
        )
        return _response.data

    async def users_ground_truth_agreement(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get ground truth agreement statistics for multiple users within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of user IDs to get ground truth agreement for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersGroundTruthAgreementStatsResponse
            Ground truth agreement statistics for multiple users

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.users_ground_truth_agreement(
                id=1,
                ids="ids",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.users_ground_truth_agreement(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def agreement_annotator(
        self, id: int, user_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AgreementAnnotatorStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement statistics for a specific annotator within a project.

        Parameters
        ----------
        id : int

        user_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgreementAnnotatorStatsResponse
            Individual annotator agreement statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.agreement_annotator(
                id=1,
                user_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.agreement_annotator(id, user_id, request_options=request_options)
        return _response.data

    async def agreement_annotators(
        self, id: int, *, ids: str, request_options: typing.Optional[RequestOptions] = None
    ) -> AgreementAnnotatorsStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get agreement statistics for multiple annotators within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get agreement scores for

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgreementAnnotatorsStatsResponse
            Multiple annotator agreement statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.agreement_annotators(
                id=1,
                ids="ids",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.agreement_annotators(id, ids=ids, request_options=request_options)
        return _response.data

    async def data_filters(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> DataFiltersStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get statistics about user data filters and their usage within a project.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DataFiltersStatsResponse
            User data filter statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.data_filters(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.data_filters(id, request_options=request_options)
        return _response.data

    async def finished_tasks(
        self, id: int, *, user_pk: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> FinishedTasksStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get statistics about finished tasks for a project.

        Parameters
        ----------
        id : int

        user_pk : typing.Optional[int]
            User ID to filter statistics by (optional)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FinishedTasksStatsResponse
            Finished tasks statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.finished_tasks(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.finished_tasks(id, user_pk=user_pk, request_options=request_options)
        return _response.data

    async def lead_time(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> LeadTimeStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get lead time statistics across the project, including average annotation time.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LeadTimeStatsResponse
            Lead time statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.lead_time(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.lead_time(id, request_options=request_options)
        return _response.data

    async def total_agreement(
        self,
        id: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TotalAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Overall or per-label total agreement across the project.

        NOTE: due to an open issue in Fern, SDK clients will raise ApiError upon handling a 204 response. As a workaround, wrap call to this function in a try-except block.

        Parameters
        ----------
        id : int

        per_label : typing.Optional[bool]
            Return agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TotalAgreementStatsResponse
            Total agreement

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.total_agreement(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.total_agreement(id, per_label=per_label, request_options=request_options)
        return _response.data

    async def update_stats(
        self,
        id: int,
        *,
        stat_type: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, typing.Any]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Start stats recalculation for given project

        Parameters
        ----------
        id : int

        stat_type : typing.Optional[str]
            Stat type to recalculate. Possible values: label, stats

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, typing.Any]
            Successful response returns job id

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.update_stats(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_stats(id, stat_type=stat_type, request_options=request_options)
        return _response.data

    async def users_prediction_agreement(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get prediction agreement statistics for multiple annotators within a project.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get agreement scores for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersPredictionAgreementStatsResponse
            Prediction agreement statistics for multiple annotators

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.users_prediction_agreement(
                id=1,
                ids="ids",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.users_prediction_agreement(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def users_review_score(
        self,
        id: int,
        *,
        ids: str,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UsersReviewScoreStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get review score and performance score statistics for multiple annotators within a project. Only allowed for accounts with reviewing features enabled.

        Parameters
        ----------
        id : int

        ids : str
            Comma separated list of annotator user IDs to get review scores for

        per_label : typing.Optional[bool]
            Per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UsersReviewScoreStatsResponse
            Review scores and performance scores for multiple annotators

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.users_review_score(
                id=1,
                ids="ids",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.users_review_score(
            id, ids=ids, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def user_prediction_agreement(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserPredictionAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get prediction agreement statistics for a specific user within a project.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserPredictionAgreementStatsResponse
            Individual user prediction agreement statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.user_prediction_agreement(
                id=1,
                user_pk=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.user_prediction_agreement(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def user_review_score(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserReviewScoreStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get review score statistics for a specific user within a project. Only allowed for accounts with reviewing features enabled.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserReviewScoreStatsResponse
            Individual user review score statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.user_review_score(
                id=1,
                user_pk=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.user_review_score(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data

    async def user_ground_truth_agreement(
        self,
        id: int,
        user_pk: int,
        *,
        per_label: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> UserGroundTruthAgreementStatsResponse:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get ground truth agreement statistics for a specific user within a project.

        Parameters
        ----------
        id : int

        user_pk : int

        per_label : typing.Optional[bool]
            Calculate agreement per label

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        UserGroundTruthAgreementStatsResponse
            Individual user ground truth agreement statistics

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.projects.stats.user_ground_truth_agreement(
                id=1,
                user_pk=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.user_ground_truth_agreement(
            id, user_pk, per_label=per_label, request_options=request_options
        )
        return _response.data
