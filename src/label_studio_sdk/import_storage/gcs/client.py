# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.pydantic_utilities import pydantic_v1
from ...core.request_options import RequestOptions
from ...types.gcs_import_storage import GcsImportStorage
from .types.gcs_create_response import GcsCreateResponse
from .types.gcs_update_response import GcsUpdateResponse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class GcsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[GcsImportStorage]:
        """
        You can connect your Google Cloud Storage bucket to Label Studio as a source storage or target storage. Use this API request to get a list of all Google import (source) storage connections for a specific project.

        The project ID can be found in the URL when viewing the project in Label Studio, or you can retrieve all project IDs using [List all projects](../projects/list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[GcsImportStorage]


        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.list()
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/gcs/", method="GET", params={"project": project}, request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(typing.List[GcsImportStorage], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GcsCreateResponse:
        """
        Create a new source storage connection to a Google Cloud Storage bucket.

        For information about the required fields and prerequisites, see [Google Cloud Storage](https://labelstud.io/guide/storage#Google-Cloud-Storage) in the Label Studio documentation.

        <Info>Ensure you configure CORS before adding cloud storage. This ensures you will be able to see the content of the data rather than just a link.</Info>

        <Tip>After you add the storage, you should validate the connection before attempting to sync your data. Your data will not be imported until you [sync your connection](sync).</Tip>

        Parameters
        ----------
        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsCreateResponse


        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.create()
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/gcs/",
            method="POST",
            json={
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def validate(
        self,
        *,
        id: typing.Optional[int] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Validate a specific GCS import storage connection. This is useful to ensure that the storage configuration settings are correct and operational before attempting to import data.

        Parameters
        ----------
        id : typing.Optional[int]
            Storage ID. If set, storage with specified ID will be updated

        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.validate()
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/gcs/validate",
            method="POST",
            json={
                "id": id,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> GcsImportStorage:
        """
        Get a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsImportStorage


        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.get(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsImportStorage, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        Deleting a source storage connection does not affect tasks with synced data in Label Studio. The sync process is designed to import new or updated tasks from the connected storage into the project, but it does not track deletions of files from the storage. Therefore, if you remove the external storage connection, the tasks that were created from that storage will remain in the project.

        If you want to remove the tasks that were synced from the external storage, you will need to delete them manually from within the Label Studio UI or use the [Delete tasks](../../tasks/delete-all-tasks) API.

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.delete(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}", method="DELETE", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(
        self,
        id: int,
        *,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GcsUpdateResponse:
        """
        Update a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsUpdateResponse


        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.update(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsUpdateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def sync(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> GcsImportStorage:
        """
        Sync tasks from a GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        Sync operations with external buckets only go one way. They either create tasks from objects in the bucket (source/import storage) or push annotations to the output bucket (export/target storage). Changing something on the bucket side doesn’t guarantee consistency in results.

        <Note>Before proceeding, you should review [How sync operations work - Source storage](https://labelstud.io/guide/storage#Source-storage) to ensure that your data remains secure and private.</Note>

        Parameters
        ----------
        id : int
            Storage ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsImportStorage


        Examples
        --------
        from label_studio_sdk.client import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.import_storage.gcs.sync(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}/sync", method="POST", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsImportStorage, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncGcsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[GcsImportStorage]:
        """
        You can connect your Google Cloud Storage bucket to Label Studio as a source storage or target storage. Use this API request to get a list of all Google import (source) storage connections for a specific project.

        The project ID can be found in the URL when viewing the project in Label Studio, or you can retrieve all project IDs using [List all projects](../projects/list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[GcsImportStorage]


        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.list()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/gcs/", method="GET", params={"project": project}, request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(typing.List[GcsImportStorage], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GcsCreateResponse:
        """
        Create a new source storage connection to a Google Cloud Storage bucket.

        For information about the required fields and prerequisites, see [Google Cloud Storage](https://labelstud.io/guide/storage#Google-Cloud-Storage) in the Label Studio documentation.

        <Info>Ensure you configure CORS before adding cloud storage. This ensures you will be able to see the content of the data rather than just a link.</Info>

        <Tip>After you add the storage, you should validate the connection before attempting to sync your data. Your data will not be imported until you [sync your connection](sync).</Tip>

        Parameters
        ----------
        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsCreateResponse


        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.create()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/gcs/",
            method="POST",
            json={
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsCreateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def validate(
        self,
        *,
        id: typing.Optional[int] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Validate a specific GCS import storage connection. This is useful to ensure that the storage configuration settings are correct and operational before attempting to import data.

        Parameters
        ----------
        id : typing.Optional[int]
            Storage ID. If set, storage with specified ID will be updated

        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.validate()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/gcs/validate",
            method="POST",
            json={
                "id": id,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> GcsImportStorage:
        """
        Get a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsImportStorage


        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.get(
            id=1,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}", method="GET", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsImportStorage, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        Deleting a source storage connection does not affect tasks with synced data in Label Studio. The sync process is designed to import new or updated tasks from the connected storage into the project, but it does not track deletions of files from the storage. Therefore, if you remove the external storage connection, the tasks that were created from that storage will remain in the project.

        If you want to remove the tasks that were synced from the external storage, you will need to delete them manually from within the Label Studio UI or use the [Delete tasks](../../tasks/delete-all-tasks) API.

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.delete(
            id=1,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}", method="DELETE", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(
        self,
        id: int,
        *,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        project: typing.Optional[int] = OMIT,
        bucket: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        google_application_credentials: typing.Optional[str] = OMIT,
        google_project_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> GcsUpdateResponse:
        """
        Update a specific GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        For more information about working with external storage, see [Sync data from external storage](https://labelstud.io/guide/storage).

        Parameters
        ----------
        id : int
            A unique integer value identifying this gcs import storage.

        regex_filter : typing.Optional[str]
            Cloud storage regex for filtering objects. You must specify it otherwise no objects will be imported.

        use_blob_urls : typing.Optional[bool]
            Interpret objects as BLOBs and generate URLs. For example, if your bucket contains images, you can use this option to generate URLs for these images. If set to False, it will read the content of the file and load it into Label Studio.

        presign : typing.Optional[bool]
            Presign URLs for direct download

        presign_ttl : typing.Optional[int]
            Presign TTL in minutes

        title : typing.Optional[str]
            Storage title

        description : typing.Optional[str]
            Storage description

        project : typing.Optional[int]
            Project ID

        bucket : typing.Optional[str]
            GCS bucket name

        prefix : typing.Optional[str]
            GCS bucket prefix

        google_application_credentials : typing.Optional[str]
            The content of GOOGLE_APPLICATION_CREDENTIALS json file. Check official Google Cloud Authentication documentation for more details.

        google_project_id : typing.Optional[str]
            Google project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsUpdateResponse


        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.update(
            id=1,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "title": title,
                "description": description,
                "project": project,
                "bucket": bucket,
                "prefix": prefix,
                "google_application_credentials": google_application_credentials,
                "google_project_id": google_project_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsUpdateResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def sync(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> GcsImportStorage:
        """
        Sync tasks from a GCS import storage connection. You will need to provide the import storage ID. You can find this using [List import storages](list).

        Sync operations with external buckets only go one way. They either create tasks from objects in the bucket (source/import storage) or push annotations to the output bucket (export/target storage). Changing something on the bucket side doesn’t guarantee consistency in results.

        <Note>Before proceeding, you should review [How sync operations work - Source storage](https://labelstud.io/guide/storage#Source-storage) to ensure that your data remains secure and private.</Note>

        Parameters
        ----------
        id : int
            Storage ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GcsImportStorage


        Examples
        --------
        from label_studio_sdk.client import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        await client.import_storage.gcs.sync(
            id=1,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/gcs/{jsonable_encoder(id)}/sync", method="POST", request_options=request_options
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(GcsImportStorage, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
