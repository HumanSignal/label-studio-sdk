# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.http_response import AsyncHttpResponse, HttpResponse
from ...core.jsonable_encoder import jsonable_encoder
from ...core.request_options import RequestOptions
from ...core.unchecked_base_model import construct_type
from ...types.auth_type_enum import AuthTypeEnum
from ...types.databricks_import_storage import DatabricksImportStorage
from ...types.status_c5a_enum import StatusC5AEnum

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class RawDatabricksClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        project: int,
        ordering: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[typing.List[DatabricksImportStorage]]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get list of all Databricks Files import storage connections.

        Parameters
        ----------
        project : int
            Project ID

        ordering : typing.Optional[str]
            Which field to use when ordering the results.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[DatabricksImportStorage]]

        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/databricks/",
            method="GET",
            params={
                "ordering": ordering,
                "project": project,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[DatabricksImportStorage],
                    construct_type(
                        type_=typing.List[DatabricksImportStorage],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def create(
        self,
        *,
        host: str,
        catalog: str,
        schema: str,
        volume: str,
        project: int,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Create a Databricks Files import storage connection.

        Parameters
        ----------
        host : str
            Databricks workspace base URL (https://...)

        catalog : str
            UC catalog name

        schema : str
            UC schema name

        volume : str
            UC volume name

        project : int
            A unique integer value identifying this project.

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[DatabricksImportStorage]

        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/databricks/",
            method="POST",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[DatabricksImportStorage]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> HttpResponse[None]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Delete a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[None]
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return HttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def update(
        self,
        id: int,
        *,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        host: typing.Optional[str] = OMIT,
        catalog: typing.Optional[str] = OMIT,
        schema: typing.Optional[str] = OMIT,
        volume: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Update a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        host : typing.Optional[str]
            Databricks workspace base URL (https://...)

        catalog : typing.Optional[str]
            UC catalog name

        schema : typing.Optional[str]
            UC schema name

        volume : typing.Optional[str]
            UC volume name

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        project : typing.Optional[int]
            A unique integer value identifying this project.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[DatabricksImportStorage]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def sync(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Sync tasks from a Databricks Files import storage.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[DatabricksImportStorage]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}/sync",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def validate(
        self,
        *,
        host: str,
        catalog: str,
        schema: str,
        volume: str,
        project: int,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[None]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Validate a specific Databricks Files import storage connection.

        Parameters
        ----------
        host : str
            Databricks workspace base URL (https://...)

        catalog : str
            UC catalog name

        schema : str
            UC schema name

        volume : str
            UC volume name

        project : int
            A unique integer value identifying this project.

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[None]
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/storages/databricks/validate",
            method="POST",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return HttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawDatabricksClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        project: int,
        ordering: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[typing.List[DatabricksImportStorage]]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get list of all Databricks Files import storage connections.

        Parameters
        ----------
        project : int
            Project ID

        ordering : typing.Optional[str]
            Which field to use when ordering the results.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[DatabricksImportStorage]]

        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/databricks/",
            method="GET",
            params={
                "ordering": ordering,
                "project": project,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[DatabricksImportStorage],
                    construct_type(
                        type_=typing.List[DatabricksImportStorage],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def create(
        self,
        *,
        host: str,
        catalog: str,
        schema: str,
        volume: str,
        project: int,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Create a Databricks Files import storage connection.

        Parameters
        ----------
        host : str
            Databricks workspace base URL (https://...)

        catalog : str
            UC catalog name

        schema : str
            UC schema name

        volume : str
            UC volume name

        project : int
            A unique integer value identifying this project.

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[DatabricksImportStorage]

        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/databricks/",
            method="POST",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Get a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[DatabricksImportStorage]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def delete(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[None]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Delete a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[None]
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return AsyncHttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def update(
        self,
        id: int,
        *,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        host: typing.Optional[str] = OMIT,
        catalog: typing.Optional[str] = OMIT,
        schema: typing.Optional[str] = OMIT,
        volume: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Update a specific Databricks Files import storage connection.

        Parameters
        ----------
        id : int

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        host : typing.Optional[str]
            Databricks workspace base URL (https://...)

        catalog : typing.Optional[str]
            UC catalog name

        schema : typing.Optional[str]
            UC schema name

        volume : typing.Optional[str]
            UC volume name

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        project : typing.Optional[int]
            A unique integer value identifying this project.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[DatabricksImportStorage]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def sync(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[DatabricksImportStorage]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Sync tasks from a Databricks Files import storage.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[DatabricksImportStorage]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/storages/databricks/{jsonable_encoder(id)}/sync",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    DatabricksImportStorage,
                    construct_type(
                        type_=DatabricksImportStorage,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def validate(
        self,
        *,
        host: str,
        catalog: str,
        schema: str,
        volume: str,
        project: int,
        synchronizable: typing.Optional[bool] = OMIT,
        auth_type: typing.Optional[AuthTypeEnum] = OMIT,
        token: typing.Optional[str] = OMIT,
        tenant_id: typing.Optional[str] = OMIT,
        client_id: typing.Optional[str] = OMIT,
        client_secret: typing.Optional[str] = OMIT,
        last_sync: typing.Optional[dt.datetime] = OMIT,
        last_sync_count: typing.Optional[int] = OMIT,
        last_sync_job: typing.Optional[str] = OMIT,
        status: typing.Optional[StatusC5AEnum] = OMIT,
        traceback: typing.Optional[str] = OMIT,
        meta: typing.Optional[typing.Any] = OMIT,
        title: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        prefix: typing.Optional[str] = OMIT,
        regex_filter: typing.Optional[str] = OMIT,
        use_blob_urls: typing.Optional[bool] = OMIT,
        verify_tls: typing.Optional[bool] = OMIT,
        request_timeout_s: typing.Optional[int] = OMIT,
        stream_chunk_bytes: typing.Optional[int] = OMIT,
        presign: typing.Optional[bool] = OMIT,
        presign_ttl: typing.Optional[int] = OMIT,
        recursive_scan: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[None]:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>
        Validate a specific Databricks Files import storage connection.

        Parameters
        ----------
        host : str
            Databricks workspace base URL (https://...)

        catalog : str
            UC catalog name

        schema : str
            UC schema name

        volume : str
            UC volume name

        project : int
            A unique integer value identifying this project.

        synchronizable : typing.Optional[bool]

        auth_type : typing.Optional[AuthTypeEnum]
            Authentication method: PAT, Databricks SP, or Azure AD SP

            * `pat` - Personal Access Token
            * `dbx_sp` - Databricks Service Principal
            * `azure_ad_sp` - Azure AD Service Principal

        token : typing.Optional[str]
            Databricks personal access token (required for PAT mode)

        tenant_id : typing.Optional[str]
            Azure AD tenant ID (required for Azure AD SP mode)

        client_id : typing.Optional[str]
            Service principal client/application ID (required for SP modes)

        client_secret : typing.Optional[str]
            Service principal client secret (required for SP modes)

        last_sync : typing.Optional[dt.datetime]
            Last sync finished time

        last_sync_count : typing.Optional[int]
            Count of tasks synced last time

        last_sync_job : typing.Optional[str]
            Last sync job ID

        status : typing.Optional[StatusC5AEnum]

        traceback : typing.Optional[str]
            Traceback report for the last failed sync

        meta : typing.Optional[typing.Any]
            Meta and debug information about storage processes

        title : typing.Optional[str]
            Cloud storage title

        description : typing.Optional[str]
            Cloud storage description

        prefix : typing.Optional[str]
            Path under the volume

        regex_filter : typing.Optional[str]
            Regex for filtering objects

        use_blob_urls : typing.Optional[bool]
            Generate blob URLs in tasks

        verify_tls : typing.Optional[bool]
            Verify TLS certificates

        request_timeout_s : typing.Optional[int]

        stream_chunk_bytes : typing.Optional[int]

        presign : typing.Optional[bool]
            Presign not supported; always proxied

        presign_ttl : typing.Optional[int]
            Unused for Databricks; kept for compatibility

        recursive_scan : typing.Optional[bool]
            Perform recursive scan

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[None]
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/storages/databricks/validate",
            method="POST",
            json={
                "synchronizable": synchronizable,
                "auth_type": auth_type,
                "token": token,
                "tenant_id": tenant_id,
                "client_id": client_id,
                "client_secret": client_secret,
                "last_sync": last_sync,
                "last_sync_count": last_sync_count,
                "last_sync_job": last_sync_job,
                "status": status,
                "traceback": traceback,
                "meta": meta,
                "title": title,
                "description": description,
                "host": host,
                "catalog": catalog,
                "schema": schema,
                "volume": volume,
                "prefix": prefix,
                "regex_filter": regex_filter,
                "use_blob_urls": use_blob_urls,
                "verify_tls": verify_tls,
                "request_timeout_s": request_timeout_s,
                "stream_chunk_bytes": stream_chunk_bytes,
                "presign": presign,
                "presign_ttl": presign_ttl,
                "recursive_scan": recursive_scan,
                "project": project,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return AsyncHttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
