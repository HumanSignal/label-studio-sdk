# This file was auto-generated by Fern from our API Definition.

import typing
from ...core.client_wrapper import SyncClientWrapper
from ...core.request_options import RequestOptions
from ...core.jsonable_encoder import jsonable_encoder
from json.decoder import JSONDecodeError
from ...core.api_error import ApiError
from ...types.third_party_model_version import ThirdPartyModelVersion
from ...core.unchecked_base_model import construct_type
from ...types.provider_enum import ProviderEnum
from ...types.inference_run_cost_estimate import InferenceRunCostEstimate
from ...types.refined_prompt_response import RefinedPromptResponse
from ...core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class VersionsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def get_default_version_name(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Get default prompt version name

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.get_default_version_name(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/get-default-version-name",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list(
        self,
        prompt_id_: int,
        *,
        prompt_id: int,
        ordering: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[ThirdPartyModelVersion]:
        """
        List all versions of a prompt.

        Parameters
        ----------
        prompt_id_ : int

        prompt_id : int
            A unique integer value identifying the model ID to list versions for.

        ordering : typing.Optional[str]
            Which field to use when ordering the results.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ThirdPartyModelVersion]


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.list(
            prompt_id_=1,
            prompt_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id_)}/versions",
            method="GET",
            params={
                "ordering": ordering,
                "prompt_id": prompt_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[ThirdPartyModelVersion],
                    construct_type(
                        type_=typing.List[ThirdPartyModelVersion],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        prompt_id: int,
        *,
        prompt: str,
        provider_model_id: str,
        title: str,
        model_provider_connection: typing.Optional[int] = OMIT,
        organization: typing.Optional[int] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        provider: typing.Optional[ProviderEnum] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ThirdPartyModelVersion:
        """
        Create a new version of a prompt.

        Parameters
        ----------
        prompt_id : int

        prompt : str
            Prompt to execute

        provider_model_id : str
            The model ID to use within the given provider, e.g. gpt-3.5

        title : str
            Model name

        model_provider_connection : typing.Optional[int]

        organization : typing.Optional[int]

        parent_model : typing.Optional[int]
            Parent model interface ID

        provider : typing.Optional[ProviderEnum]
            The model provider to use e.g. OpenAI

            * `OpenAI` - OpenAI
            * `AzureOpenAI` - AzureOpenAI
            * `AzureAIFoundry` - AzureAIFoundry
            * `VertexAI` - VertexAI
            * `Gemini` - Gemini
            * `Anthropic` - Anthropic
            * `Custom` - Custom

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.create(
            prompt_id=1,
            prompt="prompt",
            provider_model_id="provider_model_id",
            title="title",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions",
            method="POST",
            json={
                "model_provider_connection": model_provider_connection,
                "organization": organization,
                "parent_model": parent_model,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "title": title,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ThirdPartyModelVersion:
        """
        Retrieve a specific prompt of a model.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.get(
            prompt_id=1,
            version_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a prompt version by ID

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.delete(
            prompt_id=1,
            version_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(
        self,
        prompt_id: int,
        version_id: int,
        *,
        model_provider_connection: typing.Optional[int] = OMIT,
        organization: typing.Optional[int] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[ProviderEnum] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        title: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ThirdPartyModelVersion:
        """
        Update a specific prompt version by ID.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        model_provider_connection : typing.Optional[int]

        organization : typing.Optional[int]

        parent_model : typing.Optional[int]
            Parent model interface ID

        prompt : typing.Optional[str]
            Prompt to execute

        provider : typing.Optional[ProviderEnum]
            The model provider to use e.g. OpenAI

            * `OpenAI` - OpenAI
            * `AzureOpenAI` - AzureOpenAI
            * `AzureAIFoundry` - AzureAIFoundry
            * `VertexAI` - VertexAI
            * `Gemini` - Gemini
            * `Anthropic` - Anthropic
            * `Custom` - Custom

        provider_model_id : typing.Optional[str]
            The model ID to use within the given provider, e.g. gpt-3.5

        title : typing.Optional[str]
            Model name

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.update(
            prompt_id=1,
            version_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="PATCH",
            json={
                "model_provider_connection": model_provider_connection,
                "organization": organization,
                "parent_model": parent_model,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "title": title,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def cost_estimate(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> InferenceRunCostEstimate:
        """
        Get an estimate of the cost for making an inference run on the selected Prompt Version and Project/ProjectSubset

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        InferenceRunCostEstimate
            Cost estimate response

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.cost_estimate(
            prompt_id=1,
            version_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/cost-estimate",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    InferenceRunCostEstimate,
                    construct_type(
                        type_=InferenceRunCostEstimate,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_refined_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        refinement_job_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RefinedPromptResponse:
        """
        Get the refined prompt based on the `refinement_job_id`.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        refinement_job_id : typing.Optional[str]
            Refinement Job ID acquired from the `POST /api/prompts/{prompt_id}/versions/{version_id}/refine` endpoint

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RefinedPromptResponse
            Refined prompt response

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.get_refined_prompt(
            prompt_id=1,
            version_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="GET",
            params={
                "refinement_job_id": refinement_job_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RefinedPromptResponse,
                    construct_type(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def refine_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        project_id: int,
        teacher_model_name: str,
        teacher_model_provider_connection_id: int,
        async_: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RefinedPromptResponse:
        """
        Refine a prompt version using a teacher model and save the refined prompt as a new version.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        project_id : int
            Project ID to target the refined prompt for

        teacher_model_name : str
            Name of the model to use to refine the prompt

        teacher_model_provider_connection_id : int
            Model Provider Connection ID to use to refine the prompt

        async_ : typing.Optional[bool]
            Whether to run the refinement asynchronously

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RefinedPromptResponse
            Refined prompt response

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.prompts.versions.refine_prompt(
            prompt_id=1,
            version_id=1,
            project_id=1,
            teacher_model_name="teacher_model_name",
            teacher_model_provider_connection_id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="POST",
            params={
                "async": async_,
            },
            json={
                "project_id": project_id,
                "teacher_model_name": teacher_model_name,
                "teacher_model_provider_connection_id": teacher_model_provider_connection_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RefinedPromptResponse,
                    construct_type(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncVersionsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def get_default_version_name(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Get default prompt version name

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.get_default_version_name(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/get-default-version-name",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list(
        self,
        prompt_id_: int,
        *,
        prompt_id: int,
        ordering: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[ThirdPartyModelVersion]:
        """
        List all versions of a prompt.

        Parameters
        ----------
        prompt_id_ : int

        prompt_id : int
            A unique integer value identifying the model ID to list versions for.

        ordering : typing.Optional[str]
            Which field to use when ordering the results.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ThirdPartyModelVersion]


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.list(
                prompt_id_=1,
                prompt_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id_)}/versions",
            method="GET",
            params={
                "ordering": ordering,
                "prompt_id": prompt_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[ThirdPartyModelVersion],
                    construct_type(
                        type_=typing.List[ThirdPartyModelVersion],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        prompt_id: int,
        *,
        prompt: str,
        provider_model_id: str,
        title: str,
        model_provider_connection: typing.Optional[int] = OMIT,
        organization: typing.Optional[int] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        provider: typing.Optional[ProviderEnum] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ThirdPartyModelVersion:
        """
        Create a new version of a prompt.

        Parameters
        ----------
        prompt_id : int

        prompt : str
            Prompt to execute

        provider_model_id : str
            The model ID to use within the given provider, e.g. gpt-3.5

        title : str
            Model name

        model_provider_connection : typing.Optional[int]

        organization : typing.Optional[int]

        parent_model : typing.Optional[int]
            Parent model interface ID

        provider : typing.Optional[ProviderEnum]
            The model provider to use e.g. OpenAI

            * `OpenAI` - OpenAI
            * `AzureOpenAI` - AzureOpenAI
            * `AzureAIFoundry` - AzureAIFoundry
            * `VertexAI` - VertexAI
            * `Gemini` - Gemini
            * `Anthropic` - Anthropic
            * `Custom` - Custom

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.create(
                prompt_id=1,
                prompt="prompt",
                provider_model_id="provider_model_id",
                title="title",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions",
            method="POST",
            json={
                "model_provider_connection": model_provider_connection,
                "organization": organization,
                "parent_model": parent_model,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "title": title,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ThirdPartyModelVersion:
        """
        Retrieve a specific prompt of a model.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.get(
                prompt_id=1,
                version_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a prompt version by ID

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.delete(
                prompt_id=1,
                version_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(
        self,
        prompt_id: int,
        version_id: int,
        *,
        model_provider_connection: typing.Optional[int] = OMIT,
        organization: typing.Optional[int] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[ProviderEnum] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        title: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ThirdPartyModelVersion:
        """
        Update a specific prompt version by ID.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        model_provider_connection : typing.Optional[int]

        organization : typing.Optional[int]

        parent_model : typing.Optional[int]
            Parent model interface ID

        prompt : typing.Optional[str]
            Prompt to execute

        provider : typing.Optional[ProviderEnum]
            The model provider to use e.g. OpenAI

            * `OpenAI` - OpenAI
            * `AzureOpenAI` - AzureOpenAI
            * `AzureAIFoundry` - AzureAIFoundry
            * `VertexAI` - VertexAI
            * `Gemini` - Gemini
            * `Anthropic` - Anthropic
            * `Custom` - Custom

        provider_model_id : typing.Optional[str]
            The model ID to use within the given provider, e.g. gpt-3.5

        title : typing.Optional[str]
            Model name

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ThirdPartyModelVersion


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.update(
                prompt_id=1,
                version_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}",
            method="PATCH",
            json={
                "model_provider_connection": model_provider_connection,
                "organization": organization,
                "parent_model": parent_model,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "title": title,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ThirdPartyModelVersion,
                    construct_type(
                        type_=ThirdPartyModelVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def cost_estimate(
        self, prompt_id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> InferenceRunCostEstimate:
        """
        Get an estimate of the cost for making an inference run on the selected Prompt Version and Project/ProjectSubset

        Parameters
        ----------
        prompt_id : int

        version_id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        InferenceRunCostEstimate
            Cost estimate response

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.cost_estimate(
                prompt_id=1,
                version_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/cost-estimate",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    InferenceRunCostEstimate,
                    construct_type(
                        type_=InferenceRunCostEstimate,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_refined_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        refinement_job_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RefinedPromptResponse:
        """
        Get the refined prompt based on the `refinement_job_id`.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        refinement_job_id : typing.Optional[str]
            Refinement Job ID acquired from the `POST /api/prompts/{prompt_id}/versions/{version_id}/refine` endpoint

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RefinedPromptResponse
            Refined prompt response

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.get_refined_prompt(
                prompt_id=1,
                version_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="GET",
            params={
                "refinement_job_id": refinement_job_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RefinedPromptResponse,
                    construct_type(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def refine_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        project_id: int,
        teacher_model_name: str,
        teacher_model_provider_connection_id: int,
        async_: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RefinedPromptResponse:
        """
        Refine a prompt version using a teacher model and save the refined prompt as a new version.

        Parameters
        ----------
        prompt_id : int

        version_id : int

        project_id : int
            Project ID to target the refined prompt for

        teacher_model_name : str
            Name of the model to use to refine the prompt

        teacher_model_provider_connection_id : int
            Model Provider Connection ID to use to refine the prompt

        async_ : typing.Optional[bool]
            Whether to run the refinement asynchronously

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RefinedPromptResponse
            Refined prompt response

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.prompts.versions.refine_prompt(
                prompt_id=1,
                version_id=1,
                project_id=1,
                teacher_model_name="teacher_model_name",
                teacher_model_provider_connection_id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="POST",
            params={
                "async": async_,
            },
            json={
                "project_id": project_id,
                "teacher_model_name": teacher_model_name,
                "teacher_model_provider_connection_id": teacher_model_provider_connection_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    RefinedPromptResponse,
                    construct_type(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
