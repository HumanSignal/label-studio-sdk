# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.http_response import AsyncHttpResponse, HttpResponse
from ...core.jsonable_encoder import jsonable_encoder
from ...core.pydantic_utilities import parse_obj_as
from ...core.request_options import RequestOptions
from ...core.serialization import convert_and_respect_annotation_metadata
from ...types.inference_run_cost_estimate import InferenceRunCostEstimate
from ...types.prompt_version import PromptVersion
from ...types.prompt_version_created_by import PromptVersionCreatedBy
from ...types.prompt_version_organization import PromptVersionOrganization
from ...types.prompt_version_provider import PromptVersionProvider
from ...types.refined_prompt_response import RefinedPromptResponse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class RawVersionsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.List[PromptVersion]]:
        """
        Get a list of prompt versions.

        Parameters
        ----------
        id : int
            Prompt ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[PromptVersion]]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[PromptVersion],
                    parse_obj_as(
                        type_=typing.List[PromptVersion],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def create(
        self,
        id: int,
        *,
        title: typing.Optional[str] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        model_provider_connection: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[PromptVersionProvider] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        created_by: typing.Optional[PromptVersionCreatedBy] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        updated_at: typing.Optional[dt.datetime] = OMIT,
        organization: typing.Optional[PromptVersionOrganization] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[PromptVersion]:
        """
        Create a new version of a prompt.

        Parameters
        ----------
        id : int
            Prompt ID

        title : typing.Optional[str]

        parent_model : typing.Optional[int]

        model_provider_connection : typing.Optional[int]

        prompt : typing.Optional[str]

        provider : typing.Optional[PromptVersionProvider]

        provider_model_id : typing.Optional[str]

        created_by : typing.Optional[PromptVersionCreatedBy]

        created_at : typing.Optional[dt.datetime]

        updated_at : typing.Optional[dt.datetime]

        organization : typing.Optional[PromptVersionOrganization]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[PromptVersion]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions",
            method="POST",
            json={
                "title": title,
                "parent_model": parent_model,
                "model_provider_connection": model_provider_connection,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "created_by": convert_and_respect_annotation_metadata(
                    object_=created_by, annotation=PromptVersionCreatedBy, direction="write"
                ),
                "created_at": created_at,
                "updated_at": updated_at,
                "organization": convert_and_respect_annotation_metadata(
                    object_=organization, annotation=PromptVersionOrganization, direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get(
        self, id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[PromptVersion]:
        """
        Get a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[PromptVersion]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def delete(
        self, id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[None]:
        """
        Delete a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[None]
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return HttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def update(
        self,
        id: int,
        version_id: int,
        *,
        title: typing.Optional[str] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        model_provider_connection: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[PromptVersionProvider] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        created_by: typing.Optional[PromptVersionCreatedBy] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        updated_at: typing.Optional[dt.datetime] = OMIT,
        organization: typing.Optional[PromptVersionOrganization] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[PromptVersion]:
        """
        Update a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        title : typing.Optional[str]

        parent_model : typing.Optional[int]

        model_provider_connection : typing.Optional[int]

        prompt : typing.Optional[str]

        provider : typing.Optional[PromptVersionProvider]

        provider_model_id : typing.Optional[str]

        created_by : typing.Optional[PromptVersionCreatedBy]

        created_at : typing.Optional[dt.datetime]

        updated_at : typing.Optional[dt.datetime]

        organization : typing.Optional[PromptVersionOrganization]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[PromptVersion]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="PATCH",
            json={
                "title": title,
                "parent_model": parent_model,
                "model_provider_connection": model_provider_connection,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "created_by": convert_and_respect_annotation_metadata(
                    object_=created_by, annotation=PromptVersionCreatedBy, direction="write"
                ),
                "created_at": created_at,
                "updated_at": updated_at,
                "organization": convert_and_respect_annotation_metadata(
                    object_=organization, annotation=PromptVersionOrganization, direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def cost_estimate(
        self,
        prompt_id: int,
        version_id: int,
        *,
        project_id: int,
        project_subset: int,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[InferenceRunCostEstimate]:
        """
        Get cost estimate for running a prompt version on a particular project/subset

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        project_id : int
            ID of the project to get an estimate for running on

        project_subset : int
            Subset of the project to get an estimate for running on (e.g. 'All', 'Sample', or 'HasGT')

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[InferenceRunCostEstimate]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/cost-estimate",
            method="POST",
            params={
                "project_id": project_id,
                "project_subset": project_subset,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    InferenceRunCostEstimate,
                    parse_obj_as(
                        type_=InferenceRunCostEstimate,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_refined_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        refinement_job_id: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[RefinedPromptResponse]:
        """
        Get the refined prompt based on the `refinement_job_id`.

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        refinement_job_id : str
            Refinement Job ID acquired from the `POST /api/prompts/{prompt_id}/versions/{version_id}/refine` endpoint

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[RefinedPromptResponse]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="GET",
            params={
                "refinement_job_id": refinement_job_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    RefinedPromptResponse,
                    parse_obj_as(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def refine_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        async_: typing.Optional[bool] = None,
        teacher_model_provider_connection_id: typing.Optional[int] = OMIT,
        teacher_model_name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[RefinedPromptResponse]:
        """
        Refine a prompt version using a teacher model and save the refined prompt as a new version.

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Base Prompt Version ID

        async_ : typing.Optional[bool]
            Run the refinement job asynchronously

        teacher_model_provider_connection_id : typing.Optional[int]
            Model Provider Connection ID to use to refine the prompt

        teacher_model_name : typing.Optional[str]
            Name of the model to use to refine the prompt

        project_id : typing.Optional[int]
            Project ID to target the refined prompt for

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[RefinedPromptResponse]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="POST",
            params={
                "async": async_,
            },
            json={
                "teacher_model_provider_connection_id": teacher_model_provider_connection_id,
                "teacher_model_name": teacher_model_name,
                "project_id": project_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    RefinedPromptResponse,
                    parse_obj_as(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawVersionsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.List[PromptVersion]]:
        """
        Get a list of prompt versions.

        Parameters
        ----------
        id : int
            Prompt ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[PromptVersion]]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[PromptVersion],
                    parse_obj_as(
                        type_=typing.List[PromptVersion],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def create(
        self,
        id: int,
        *,
        title: typing.Optional[str] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        model_provider_connection: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[PromptVersionProvider] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        created_by: typing.Optional[PromptVersionCreatedBy] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        updated_at: typing.Optional[dt.datetime] = OMIT,
        organization: typing.Optional[PromptVersionOrganization] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[PromptVersion]:
        """
        Create a new version of a prompt.

        Parameters
        ----------
        id : int
            Prompt ID

        title : typing.Optional[str]

        parent_model : typing.Optional[int]

        model_provider_connection : typing.Optional[int]

        prompt : typing.Optional[str]

        provider : typing.Optional[PromptVersionProvider]

        provider_model_id : typing.Optional[str]

        created_by : typing.Optional[PromptVersionCreatedBy]

        created_at : typing.Optional[dt.datetime]

        updated_at : typing.Optional[dt.datetime]

        organization : typing.Optional[PromptVersionOrganization]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[PromptVersion]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions",
            method="POST",
            json={
                "title": title,
                "parent_model": parent_model,
                "model_provider_connection": model_provider_connection,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "created_by": convert_and_respect_annotation_metadata(
                    object_=created_by, annotation=PromptVersionCreatedBy, direction="write"
                ),
                "created_at": created_at,
                "updated_at": updated_at,
                "organization": convert_and_respect_annotation_metadata(
                    object_=organization, annotation=PromptVersionOrganization, direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get(
        self, id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[PromptVersion]:
        """
        Get a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[PromptVersion]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def delete(
        self, id: int, version_id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[None]:
        """
        Delete a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[None]
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return AsyncHttpResponse(response=_response, data=None)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def update(
        self,
        id: int,
        version_id: int,
        *,
        title: typing.Optional[str] = OMIT,
        parent_model: typing.Optional[int] = OMIT,
        model_provider_connection: typing.Optional[int] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        provider: typing.Optional[PromptVersionProvider] = OMIT,
        provider_model_id: typing.Optional[str] = OMIT,
        created_by: typing.Optional[PromptVersionCreatedBy] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        updated_at: typing.Optional[dt.datetime] = OMIT,
        organization: typing.Optional[PromptVersionOrganization] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[PromptVersion]:
        """
        Update a prompt version by ID.

        Parameters
        ----------
        id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        title : typing.Optional[str]

        parent_model : typing.Optional[int]

        model_provider_connection : typing.Optional[int]

        prompt : typing.Optional[str]

        provider : typing.Optional[PromptVersionProvider]

        provider_model_id : typing.Optional[str]

        created_by : typing.Optional[PromptVersionCreatedBy]

        created_at : typing.Optional[dt.datetime]

        updated_at : typing.Optional[dt.datetime]

        organization : typing.Optional[PromptVersionOrganization]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[PromptVersion]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}",
            method="PATCH",
            json={
                "title": title,
                "parent_model": parent_model,
                "model_provider_connection": model_provider_connection,
                "prompt": prompt,
                "provider": provider,
                "provider_model_id": provider_model_id,
                "created_by": convert_and_respect_annotation_metadata(
                    object_=created_by, annotation=PromptVersionCreatedBy, direction="write"
                ),
                "created_at": created_at,
                "updated_at": updated_at,
                "organization": convert_and_respect_annotation_metadata(
                    object_=organization, annotation=PromptVersionOrganization, direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PromptVersion,
                    parse_obj_as(
                        type_=PromptVersion,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def cost_estimate(
        self,
        prompt_id: int,
        version_id: int,
        *,
        project_id: int,
        project_subset: int,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[InferenceRunCostEstimate]:
        """
        Get cost estimate for running a prompt version on a particular project/subset

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        project_id : int
            ID of the project to get an estimate for running on

        project_subset : int
            Subset of the project to get an estimate for running on (e.g. 'All', 'Sample', or 'HasGT')

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[InferenceRunCostEstimate]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/cost-estimate",
            method="POST",
            params={
                "project_id": project_id,
                "project_subset": project_subset,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    InferenceRunCostEstimate,
                    parse_obj_as(
                        type_=InferenceRunCostEstimate,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_refined_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        refinement_job_id: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[RefinedPromptResponse]:
        """
        Get the refined prompt based on the `refinement_job_id`.

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Prompt Version ID

        refinement_job_id : str
            Refinement Job ID acquired from the `POST /api/prompts/{prompt_id}/versions/{version_id}/refine` endpoint

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[RefinedPromptResponse]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="GET",
            params={
                "refinement_job_id": refinement_job_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    RefinedPromptResponse,
                    parse_obj_as(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def refine_prompt(
        self,
        prompt_id: int,
        version_id: int,
        *,
        async_: typing.Optional[bool] = None,
        teacher_model_provider_connection_id: typing.Optional[int] = OMIT,
        teacher_model_name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[RefinedPromptResponse]:
        """
        Refine a prompt version using a teacher model and save the refined prompt as a new version.

        Parameters
        ----------
        prompt_id : int
            Prompt ID

        version_id : int
            Base Prompt Version ID

        async_ : typing.Optional[bool]
            Run the refinement job asynchronously

        teacher_model_provider_connection_id : typing.Optional[int]
            Model Provider Connection ID to use to refine the prompt

        teacher_model_name : typing.Optional[str]
            Name of the model to use to refine the prompt

        project_id : typing.Optional[int]
            Project ID to target the refined prompt for

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[RefinedPromptResponse]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/prompts/{jsonable_encoder(prompt_id)}/versions/{jsonable_encoder(version_id)}/refine",
            method="POST",
            params={
                "async": async_,
            },
            json={
                "teacher_model_provider_connection_id": teacher_model_provider_connection_id,
                "teacher_model_name": teacher_model_name,
                "project_id": project_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    RefinedPromptResponse,
                    parse_obj_as(
                        type_=RefinedPromptResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
