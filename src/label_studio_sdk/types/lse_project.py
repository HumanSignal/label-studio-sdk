# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.unchecked_base_model import UncheckedBaseModel
from .agreement_methodology_enum import AgreementMethodologyEnum
from .assignment_settings import AssignmentSettings
from .review_settings import ReviewSettings
from .sampling_de5enum import SamplingDe5Enum
from .skip_queue_enum import SkipQueueEnum
from .user_simple import UserSimple


class LseProject(UncheckedBaseModel):
    """
    Serializer get numbers from project queryset annotation,
    make sure, that you use correct one(Project.objects.with_counts())
    """

    agreement_methodology: typing.Optional[AgreementMethodologyEnum] = pydantic.Field(default=None)
    """
    Methodology (Consensus / Pairwise Averaging)
    
    * `consensus` - Consensus
    * `pairwise` - Pairwise Averaging
    """

    agreement_threshold: typing.Optional[str] = pydantic.Field(default=None)
    """
    Agreement threshold
    """

    annotation_limit_count: typing.Optional[int] = pydantic.Field(default=None)
    """
    Limit by number of tasks
    """

    annotation_limit_percent: typing.Optional[str] = pydantic.Field(default=None)
    """
    Limit by percentage of tasks
    """

    annotator_evaluation_continuous_tasks: typing.Optional[int] = pydantic.Field(default=None)
    """
    Continuous Evaluation: Required tasks
    """

    annotator_evaluation_enabled: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Evaluate all annotators against ground truth
    """

    annotator_evaluation_minimum_score: typing.Optional[str] = pydantic.Field(default=None)
    """
    Score required to pass evaluation
    """

    annotator_evaluation_minimum_tasks: typing.Optional[int] = pydantic.Field(default=None)
    """
    Number of tasks for evaluation
    """

    annotator_evaluation_onboarding_tasks: typing.Optional[int] = pydantic.Field(default=None)
    """
    Onboarding Evaluation: Required tasks
    """

    assignment_settings: AssignmentSettings
    color: typing.Optional[str] = pydantic.Field(default=None)
    """
    Color
    """

    comment_classification_config: typing.Optional[str] = None
    config_has_control_tags: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Flag to detect is project ready for labeling
    """

    config_suitable_for_bulk_annotation: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Flag to detect is project ready for bulk annotation
    """

    control_weights: typing.Optional[typing.Dict[str, typing.Any]] = pydantic.Field(default=None)
    """
    Dict of weights for each control tag in metric calculation.
    """

    created_at: typing.Optional[dt.datetime] = None
    created_by: typing.Optional[UserSimple] = pydantic.Field(default=None)
    """
    Project owner
    """

    custom_script: typing.Optional[str] = pydantic.Field(default=None)
    """
    Plugins
    """

    custom_task_lock_ttl: typing.Optional[int] = pydantic.Field(default=None)
    """
    Task reservation time. TTL in seconds (UI displays and edits this value in minutes).
    """

    data_types: typing.Optional[typing.Dict[str, typing.Any]] = None
    description: typing.Optional[str] = pydantic.Field(default=None)
    """
    Description
    """

    duplication_done: typing.Optional[bool] = None
    duplication_status: typing.Optional[str] = None
    enable_empty_annotation: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Allow empty annotations
    """

    evaluate_predictions_automatically: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Retrieve and display predictions when loading a task
    """

    expert_instruction: typing.Optional[str] = pydantic.Field(default=None)
    """
    Instructions
    """

    finished_task_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Finished tasks
    """

    ground_truth_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Honeypot annotation number in project
    """

    id: typing.Optional[int] = None
    is_draft: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether or not the project is in the middle of being created
    """

    is_published: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether or not the project is published to annotators
    """

    label_config: typing.Optional[str] = pydantic.Field(default=None)
    """
    Labeling Configuration
    """

    max_additional_annotators_assignable: typing.Optional[int] = pydantic.Field(default=None)
    """
    Maximum additional annotators
    """

    maximum_annotations: typing.Optional[int] = pydantic.Field(default=None)
    """
    Annotations per task
    """

    members: typing.Optional[str] = None
    members_count: typing.Optional[int] = None
    min_annotations_to_start_training: typing.Optional[int] = pydantic.Field(default=None)
    """
    Minimum number of completed tasks after which model training is started
    """

    model_version: typing.Optional[str] = pydantic.Field(default=None)
    """
    Machine learning model version
    """

    num_tasks_with_annotations: typing.Optional[int] = None
    organization: typing.Optional[int] = None
    overlap_cohort_percentage: typing.Optional[int] = pydantic.Field(default=None)
    """
    Annotations per task coverage
    """

    parsed_label_config: typing.Optional[typing.Dict[str, typing.Any]] = pydantic.Field(default=None)
    """
    JSON-formatted labeling configuration
    """

    pause_on_failed_annotator_evaluation: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Pause annotator on failed evaluation
    """

    pinned_at: typing.Optional[dt.datetime] = pydantic.Field(default=None)
    """
    Pinned date and time
    """

    prompts: typing.Optional[str] = None
    queue_done: typing.Optional[str] = None
    queue_left: typing.Optional[str] = None
    queue_total: typing.Optional[str] = None
    require_comment_on_skip: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Require comment to skip
    """

    reveal_preannotations_interactively: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Reveal pre-annotations interactively
    """

    review_settings: ReviewSettings
    reviewer_queue_total: typing.Optional[str] = None
    sampling: typing.Optional[SamplingDe5Enum] = None
    show_annotation_history: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Show Data Manager to Annotators
    """

    show_collab_predictions: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Use predictions to pre-label Tasks
    """

    show_ground_truth_first: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Onboarding mode (true): show ground truth tasks first in the labeling stream
    """

    show_instruction: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Show instructions before labeling
    """

    show_overlap_first: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Show tasks with overlap first
    """

    show_skip_button: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Allow skipping tasks
    """

    show_unused_data_columns_to_annotators: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Show only columns used in labeling configuration to Annotators. API uses inverse field semantics here: set false to show only used columns, set true to show all task.data columns.
    """

    skip_queue: typing.Optional[SkipQueueEnum] = None
    skipped_annotations_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Skipped by collaborators annotation number in project
    """

    start_training_on_annotation_update: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Start model training after any annotations are submitted or updated
    """

    state: typing.Optional[str] = None
    strict_task_overlap: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Enforce strict overlap limit
    """

    task_data_login: typing.Optional[str] = pydantic.Field(default=None)
    """
    Login
    """

    task_data_password: typing.Optional[str] = pydantic.Field(default=None)
    """
    Password
    """

    task_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Total task number in project
    """

    title: typing.Optional[str] = pydantic.Field(default=None)
    """
    Project Name
    """

    total_annotations_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Total annotations number in project including skipped_annotations_number and ground_truth_number.
    """

    total_predictions_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Total predictions number in project including skipped_annotations_number, ground_truth_number, and useful_annotation_number.
    """

    useful_annotation_number: typing.Optional[int] = pydantic.Field(default=None)
    """
    Useful annotation number in project not including skipped_annotations_number and ground_truth_number. Total annotations = annotation_number + skipped_annotations_number + ground_truth_number
    """

    workspace: typing.Optional[str] = None
    workspace_title: typing.Optional[str] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
