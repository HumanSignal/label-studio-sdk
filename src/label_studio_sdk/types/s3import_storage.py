# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..core.datetime_utils import serialize_datetime
from ..core.pydantic_utilities import deep_union_pydantic_dicts, pydantic_v1
from .s3import_storage_status import S3ImportStorageStatus


class S3ImportStorage(pydantic_v1.BaseModel):
    id: typing.Optional[int] = None
    type: typing.Optional[str] = None
    synchronizable: typing.Optional[bool] = None
    presign: typing.Optional[bool] = None
    last_sync: typing.Optional[dt.datetime] = pydantic_v1.Field(default=None)
    """
    Last sync finished time
    """

    last_sync_count: typing.Optional[int] = pydantic_v1.Field(default=None)
    """
    Count of tasks synced last time
    """

    last_sync_job: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    Last sync job ID
    """

    status: typing.Optional[S3ImportStorageStatus] = None
    traceback: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    Traceback report for the last failed sync
    """

    meta: typing.Optional[typing.Dict[str, typing.Any]] = pydantic_v1.Field(default=None)
    """
    Meta and debug information about storage processes
    """

    title: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    Cloud storage title
    """

    description: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    Cloud storage description
    """

    created_at: typing.Optional[dt.datetime] = pydantic_v1.Field(default=None)
    """
    Creation time
    """

    bucket: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    S3 bucket name
    """

    prefix: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    S3 bucket prefix
    """

    regex_filter: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    Cloud storage regex for filtering objects
    """

    use_blob_urls: typing.Optional[bool] = pydantic_v1.Field(default=None)
    """
    Interpret objects as BLOBs and generate URLs
    """

    aws_access_key_id: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    AWS_ACCESS_KEY_ID
    """

    aws_secret_access_key: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    AWS_SECRET_ACCESS_KEY
    """

    aws_session_token: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    AWS_SESSION_TOKEN
    """

    aws_sse_kms_key_id: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    AWS SSE KMS Key ID
    """

    region_name: typing.Optional[str] = pydantic_v1.Field(default=None)
    """
    AWS Region
    """

    s3endpoint: typing.Optional[str] = pydantic_v1.Field(alias="s3_endpoint", default=None)
    """
    S3 Endpoint
    """

    presign_ttl: typing.Optional[int] = pydantic_v1.Field(default=None)
    """
    Presigned URLs TTL (in minutes)
    """

    recursive_scan: typing.Optional[bool] = pydantic_v1.Field(default=None)
    """
    Perform recursive scan over the bucket content
    """

    project: int = pydantic_v1.Field()
    """
    A unique integer value identifying this project.
    """

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults_exclude_unset: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        kwargs_with_defaults_exclude_none: typing.Any = {"by_alias": True, "exclude_none": True, **kwargs}

        return deep_union_pydantic_dicts(
            super().dict(**kwargs_with_defaults_exclude_unset), super().dict(**kwargs_with_defaults_exclude_none)
        )

    class Config:
        frozen = True
        smart_union = True
        allow_population_by_field_name = True
        populate_by_name = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
