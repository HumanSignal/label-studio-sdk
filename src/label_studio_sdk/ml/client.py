# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.ml_backend import MlBackend
from .raw_client import AsyncRawMlClient, RawMlClient
from .types.create_ml_request_auth_method import CreateMlRequestAuthMethod
from .types.list_model_versions_ml_response import ListModelVersionsMlResponse
from .types.update_ml_request_auth_method import UpdateMlRequestAuthMethod

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class MlClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawMlClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawMlClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawMlClient
        """
        return self._raw_client

    def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[MlBackend]:
        """

            List all configured ML backends for a specific project by ID.
            Use the following cURL command:
            ```bash
            curl https://localhost:8080/api/ml?project={project_id} -H 'Authorization: Token abc123'


        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[MlBackend]


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.list()
        """
        _response = self._raw_client.list(project=project, request_options=request_options)
        return _response.data

    def create(
        self,
        *,
        auth_method: typing.Optional[CreateMlRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Add an ML backend to a project using the Label Studio UI or by sending a POST request using the following cURL 
            command:
            ```bash
            curl -X POST -H 'Content-type: application/json' https://localhost:8080/api/ml -H 'Authorization: Token abc123'\\
            --data '{"url": "http://localhost:9090", "project": {project_id}}' 
            
        
        Parameters
        ----------
        auth_method : typing.Optional[CreateMlRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Any]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        from label_studio_sdk import LabelStudio
        
        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.create()
        """
        _response = self._raw_client.create(
            auth_method=auth_method,
            basic_auth_pass=basic_auth_pass,
            basic_auth_user=basic_auth_user,
            description=description,
            extra_params=extra_params,
            is_interactive=is_interactive,
            project=project,
            timeout=timeout,
            title=title,
            url=url,
            request_options=request_options,
        )
        return _response.data

    def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> MlBackend:
        """

            Get details about a specific ML backend connection by ID. For example, make a GET request using the
            following cURL command:
            ```bash
            curl https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlBackend


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.get(
            id=1,
        )
        """
        _response = self._raw_client.get(id, request_options=request_options)
        return _response.data

    def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """

            Remove an existing ML backend connection by ID. For example, use the
            following cURL command:
            ```bash
            curl -X DELETE https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.delete(
            id=1,
        )
        """
        _response = self._raw_client.delete(id, request_options=request_options)
        return _response.data

    def update(
        self,
        id: int,
        *,
        auth_method: typing.Optional[UpdateMlRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Update ML backend parameters using the Label Studio UI or by sending a PATCH request using the following cURL command:
            ```bash
            curl -X PATCH -H 'Content-type: application/json' https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'\\
            --data '{"url": "http://localhost:9091"}' 
            
        
        Parameters
        ----------
        id : int
        
        auth_method : typing.Optional[UpdateMlRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Any]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        from label_studio_sdk import LabelStudio
        
        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.update(
            id=1,
        )
        """
        _response = self._raw_client.update(
            id,
            auth_method=auth_method,
            basic_auth_pass=basic_auth_pass,
            basic_auth_user=basic_auth_user,
            description=description,
            extra_params=extra_params,
            is_interactive=is_interactive,
            project=project,
            timeout=timeout,
            title=title,
            url=url,
            request_options=request_options,
        )
        return _response.data

    def predict_interactive(
        self,
        id: int,
        *,
        task: int,
        context: typing.Optional[typing.Any] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                Send a request to the machine learning backend set up to be used for interactive preannotations to retrieve a
                predicted region based on annotator input.
                See [set up machine learning](https://labelstud.io/guide/ml.html#Get-interactive-preannotations) for more.


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        task : int
            ID of task to annotate

        context : typing.Optional[typing.Any]
            Context for ML model

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.predict_interactive(
            id=1,
            task=1,
        )
        """
        _response = self._raw_client.predict_interactive(
            id, task=task, context=context, request_options=request_options
        )
        return _response.data

    def predict_all_tasks(
        self,
        id: int,
        *,
        batch_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>


        Create predictions for all tasks using a specific ML backend so that you can set up an active learning strategy based on the confidence or uncertainty scores associated with the predictions. Creating predictions requires a Label Studio ML backend set up and configured for your project.

        See [Set up machine learning](https://labelstud.io/guide/ml.html) for more details about a Label Studio ML backend.

        Reference the ML backend ID in the path of this API call. Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).

        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        batch_size : typing.Optional[int]
            Computed number of tasks without predictions that the ML backend needs to predict.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.predict_all_tasks(
            id=1,
        )
        """
        _response = self._raw_client.predict_all_tasks(id, batch_size=batch_size, request_options=request_options)
        return _response.data

    def train(
        self,
        id: int,
        *,
        use_ground_truth: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                After you add an ML backend, call this API with the ML backend ID to start training with
                already-labeled tasks.

                Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        use_ground_truth : typing.Optional[bool]
            Whether to include ground truth annotations in training

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.train(
            id=1,
        )
        """
        _response = self._raw_client.train(id, use_ground_truth=use_ground_truth, request_options=request_options)
        return _response.data

    def list_model_versions(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ListModelVersionsMlResponse:
        """
        Get available versions of the model.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListModelVersionsMlResponse
            List of available versions.

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.list_model_versions(
            id=1,
        )
        """
        _response = self._raw_client.list_model_versions(id, request_options=request_options)
        return _response.data


class AsyncMlClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawMlClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawMlClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawMlClient
        """
        return self._raw_client

    async def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[MlBackend]:
        """

            List all configured ML backends for a specific project by ID.
            Use the following cURL command:
            ```bash
            curl https://localhost:8080/api/ml?project={project_id} -H 'Authorization: Token abc123'


        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[MlBackend]


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.list()


        asyncio.run(main())
        """
        _response = await self._raw_client.list(project=project, request_options=request_options)
        return _response.data

    async def create(
        self,
        *,
        auth_method: typing.Optional[CreateMlRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Add an ML backend to a project using the Label Studio UI or by sending a POST request using the following cURL 
            command:
            ```bash
            curl -X POST -H 'Content-type: application/json' https://localhost:8080/api/ml -H 'Authorization: Token abc123'\\
            --data '{"url": "http://localhost:9090", "project": {project_id}}' 
            
        
        Parameters
        ----------
        auth_method : typing.Optional[CreateMlRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Any]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        import asyncio
        
        from label_studio_sdk import AsyncLabelStudio
        
        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        
        
        async def main() -> None:
            await client.ml.create()
        
        
        asyncio.run(main())
        """
        _response = await self._raw_client.create(
            auth_method=auth_method,
            basic_auth_pass=basic_auth_pass,
            basic_auth_user=basic_auth_user,
            description=description,
            extra_params=extra_params,
            is_interactive=is_interactive,
            project=project,
            timeout=timeout,
            title=title,
            url=url,
            request_options=request_options,
        )
        return _response.data

    async def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> MlBackend:
        """

            Get details about a specific ML backend connection by ID. For example, make a GET request using the
            following cURL command:
            ```bash
            curl https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlBackend


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.get(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get(id, request_options=request_options)
        return _response.data

    async def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """

            Remove an existing ML backend connection by ID. For example, use the
            following cURL command:
            ```bash
            curl -X DELETE https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.delete(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete(id, request_options=request_options)
        return _response.data

    async def update(
        self,
        id: int,
        *,
        auth_method: typing.Optional[UpdateMlRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Update ML backend parameters using the Label Studio UI or by sending a PATCH request using the following cURL command:
            ```bash
            curl -X PATCH -H 'Content-type: application/json' https://localhost:8080/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'\\
            --data '{"url": "http://localhost:9091"}' 
            
        
        Parameters
        ----------
        id : int
        
        auth_method : typing.Optional[UpdateMlRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Any]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        import asyncio
        
        from label_studio_sdk import AsyncLabelStudio
        
        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        
        
        async def main() -> None:
            await client.ml.update(
                id=1,
            )
        
        
        asyncio.run(main())
        """
        _response = await self._raw_client.update(
            id,
            auth_method=auth_method,
            basic_auth_pass=basic_auth_pass,
            basic_auth_user=basic_auth_user,
            description=description,
            extra_params=extra_params,
            is_interactive=is_interactive,
            project=project,
            timeout=timeout,
            title=title,
            url=url,
            request_options=request_options,
        )
        return _response.data

    async def predict_interactive(
        self,
        id: int,
        *,
        task: int,
        context: typing.Optional[typing.Any] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                Send a request to the machine learning backend set up to be used for interactive preannotations to retrieve a
                predicted region based on annotator input.
                See [set up machine learning](https://labelstud.io/guide/ml.html#Get-interactive-preannotations) for more.


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        task : int
            ID of task to annotate

        context : typing.Optional[typing.Any]
            Context for ML model

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.predict_interactive(
                id=1,
                task=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.predict_interactive(
            id, task=task, context=context, request_options=request_options
        )
        return _response.data

    async def predict_all_tasks(
        self,
        id: int,
        *,
        batch_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        <Card href="https://humansignal.com/goenterprise">
                <img style="pointer-events: none; margin-left: 0px; margin-right: 0px;" src="https://docs.humansignal.com/images/badge.svg" alt="Label Studio Enterprise badge"/>
                <p style="margin-top: 10px; font-size: 14px;">
                    This endpoint is not available in Label Studio Community Edition. [Learn more about Label Studio Enterprise](https://humansignal.com/goenterprise)
                </p>
            </Card>


        Create predictions for all tasks using a specific ML backend so that you can set up an active learning strategy based on the confidence or uncertainty scores associated with the predictions. Creating predictions requires a Label Studio ML backend set up and configured for your project.

        See [Set up machine learning](https://labelstud.io/guide/ml.html) for more details about a Label Studio ML backend.

        Reference the ML backend ID in the path of this API call. Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).

        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        batch_size : typing.Optional[int]
            Computed number of tasks without predictions that the ML backend needs to predict.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.predict_all_tasks(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.predict_all_tasks(id, batch_size=batch_size, request_options=request_options)
        return _response.data

    async def train(
        self,
        id: int,
        *,
        use_ground_truth: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                After you add an ML backend, call this API with the ML backend ID to start training with
                already-labeled tasks.

                Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        use_ground_truth : typing.Optional[bool]
            Whether to include ground truth annotations in training

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.train(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.train(id, use_ground_truth=use_ground_truth, request_options=request_options)
        return _response.data

    async def list_model_versions(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ListModelVersionsMlResponse:
        """
        Get available versions of the model.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListModelVersionsMlResponse
            List of available versions.

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.list_model_versions(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_model_versions(id, request_options=request_options)
        return _response.data
