# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.ml_backend import MlBackend
from ..core.unchecked_base_model import construct_type
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.ml_create_request_auth_method import MlCreateRequestAuthMethod
from ..core.jsonable_encoder import jsonable_encoder
from .types.ml_update_request_auth_method import MlUpdateRequestAuthMethod
from ..errors.internal_server_error import InternalServerError
from .types.ml_list_model_versions_response import MlListModelVersionsResponse
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class MlClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[MlBackend]:
        """

            List all configured ML backends for a specific project by ID.
            Use the following cURL command:
            ```bash
            curl http://localhost:8000/api/ml?project={project_id} -H 'Authorization: Token abc123'


        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[MlBackend]


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.list()
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/ml/",
            method="GET",
            params={
                "project": project,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[MlBackend],
                    construct_type(
                        type_=typing.List[MlBackend],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        auth_method: typing.Optional[MlCreateRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Add an ML backend to a project using the Label Studio UI or by sending a POST request using the following cURL 
            command:
            ```bash
            curl -X POST -H 'Content-type: application/json' http://localhost:8000/api/ml -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9090", "project": {project_id}}' 
            
        
        Parameters
        ----------
        auth_method : typing.Optional[MlCreateRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        from label_studio_sdk import LabelStudio
        
        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.create()
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/ml/",
            method="POST",
            json={
                "auth_method": auth_method,
                "basic_auth_pass": basic_auth_pass,
                "basic_auth_user": basic_auth_user,
                "description": description,
                "extra_params": extra_params,
                "is_interactive": is_interactive,
                "project": project,
                "timeout": timeout,
                "title": title,
                "url": url,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> MlBackend:
        """

            Get details about a specific ML backend connection by ID. For example, make a GET request using the
            following cURL command:
            ```bash
            curl http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlBackend


        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.get(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """

            Remove an existing ML backend connection by ID. For example, use the
            following cURL command:
            ```bash
            curl -X DELETE http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.delete(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(
        self,
        id: int,
        *,
        auth_method: typing.Optional[MlUpdateRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Update ML backend parameters using the Label Studio UI or by sending a PATCH request using the following cURL command:
            ```bash
            curl -X PATCH -H 'Content-type: application/json' http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9091"}' 
            
        
        Parameters
        ----------
        id : int
        
        auth_method : typing.Optional[MlUpdateRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        from label_studio_sdk import LabelStudio
        
        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.update(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "auth_method": auth_method,
                "basic_auth_pass": basic_auth_pass,
                "basic_auth_user": basic_auth_user,
                "description": description,
                "extra_params": extra_params,
                "is_interactive": is_interactive,
                "project": project,
                "timeout": timeout,
                "title": title,
                "url": url,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def predict_interactive(
        self,
        id: int,
        *,
        task: int,
        context: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                Send a request to the machine learning backend set up to be used for interactive preannotations to retrieve a
                predicted region based on annotator input.
                See [set up machine learning](https://labelstud.io/guide/ml.html#Get-interactive-preannotations) for more.


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        task : int
            ID of task to annotate

        context : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.predict_interactive(
            id=1,
            task=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/interactive-annotating",
            method="POST",
            json={
                "context": context,
                "task": task,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def train(
        self,
        id: int,
        *,
        use_ground_truth: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                After you add an ML backend, call this API with the ML backend ID to start training with
                already-labeled tasks.

                Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        use_ground_truth : typing.Optional[bool]
            Whether to include ground truth annotations in training

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.train(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/train",
            method="POST",
            json={
                "use_ground_truth": use_ground_truth,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        str,
                        construct_type(
                            type_=str,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_model_versions(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> MlListModelVersionsResponse:
        """
        Get available versions of the model.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlListModelVersionsResponse
            List of available versions.

        Examples
        --------
        from label_studio_sdk import LabelStudio

        client = LabelStudio(
            api_key="YOUR_API_KEY",
        )
        client.ml.list_model_versions(
            id=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/versions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlListModelVersionsResponse,
                    construct_type(
                        type_=MlListModelVersionsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncMlClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self, *, project: typing.Optional[int] = None, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[MlBackend]:
        """

            List all configured ML backends for a specific project by ID.
            Use the following cURL command:
            ```bash
            curl http://localhost:8000/api/ml?project={project_id} -H 'Authorization: Token abc123'


        Parameters
        ----------
        project : typing.Optional[int]
            Project ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[MlBackend]


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.list()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/ml/",
            method="GET",
            params={
                "project": project,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[MlBackend],
                    construct_type(
                        type_=typing.List[MlBackend],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        auth_method: typing.Optional[MlCreateRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Add an ML backend to a project using the Label Studio UI or by sending a POST request using the following cURL 
            command:
            ```bash
            curl -X POST -H 'Content-type: application/json' http://localhost:8000/api/ml -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9090", "project": {project_id}}' 
            
        
        Parameters
        ----------
        auth_method : typing.Optional[MlCreateRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        import asyncio
        
        from label_studio_sdk import AsyncLabelStudio
        
        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        
        
        async def main() -> None:
            await client.ml.create()
        
        
        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/ml/",
            method="POST",
            json={
                "auth_method": auth_method,
                "basic_auth_pass": basic_auth_pass,
                "basic_auth_user": basic_auth_user,
                "description": description,
                "extra_params": extra_params,
                "is_interactive": is_interactive,
                "project": project,
                "timeout": timeout,
                "title": title,
                "url": url,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> MlBackend:
        """

            Get details about a specific ML backend connection by ID. For example, make a GET request using the
            following cURL command:
            ```bash
            curl http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlBackend


        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.get(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, id: int, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """

            Remove an existing ML backend connection by ID. For example, use the
            following cURL command:
            ```bash
            curl -X DELETE http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'


        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.delete(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(
        self,
        id: int,
        *,
        auth_method: typing.Optional[MlUpdateRequestAuthMethod] = OMIT,
        basic_auth_pass: typing.Optional[str] = OMIT,
        basic_auth_user: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        extra_params: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        is_interactive: typing.Optional[bool] = OMIT,
        project: typing.Optional[int] = OMIT,
        timeout: typing.Optional[int] = OMIT,
        title: typing.Optional[str] = OMIT,
        url: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MlBackend:
        """
        
            Update ML backend parameters using the Label Studio UI or by sending a PATCH request using the following cURL command:
            ```bash
            curl -X PATCH -H 'Content-type: application/json' http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9091"}' 
            
        
        Parameters
        ----------
        id : int
        
        auth_method : typing.Optional[MlUpdateRequestAuthMethod]
            Auth method
        
        basic_auth_pass : typing.Optional[str]
            Basic auth password
        
        basic_auth_user : typing.Optional[str]
            Basic auth user
        
        description : typing.Optional[str]
            Description
        
        extra_params : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Extra parameters
        
        is_interactive : typing.Optional[bool]
            Is interactive
        
        project : typing.Optional[int]
            Project ID
        
        timeout : typing.Optional[int]
            Response model timeout
        
        title : typing.Optional[str]
            Title
        
        url : typing.Optional[str]
            ML backend URL
        
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.
        
        Returns
        -------
        MlBackend
            
        
        Examples
        --------
        import asyncio
        
        from label_studio_sdk import AsyncLabelStudio
        
        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )
        
        
        async def main() -> None:
            await client.ml.update(
                id=1,
            )
        
        
        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "auth_method": auth_method,
                "basic_auth_pass": basic_auth_pass,
                "basic_auth_user": basic_auth_user,
                "description": description,
                "extra_params": extra_params,
                "is_interactive": is_interactive,
                "project": project,
                "timeout": timeout,
                "title": title,
                "url": url,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlBackend,
                    construct_type(
                        type_=MlBackend,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def predict_interactive(
        self,
        id: int,
        *,
        task: int,
        context: typing.Optional[typing.Optional[typing.Any]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                Send a request to the machine learning backend set up to be used for interactive preannotations to retrieve a
                predicted region based on annotator input.
                See [set up machine learning](https://labelstud.io/guide/ml.html#Get-interactive-preannotations) for more.


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        task : int
            ID of task to annotate

        context : typing.Optional[typing.Optional[typing.Any]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.predict_interactive(
                id=1,
                task=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/interactive-annotating",
            method="POST",
            json={
                "context": context,
                "task": task,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def train(
        self,
        id: int,
        *,
        use_ground_truth: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """

                After you add an ML backend, call this API with the ML backend ID to start training with
                already-labeled tasks.

                Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).


        Parameters
        ----------
        id : int
            A unique integer value identifying this ML backend.

        use_ground_truth : typing.Optional[bool]
            Whether to include ground truth annotations in training

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.train(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/train",
            method="POST",
            json={
                "use_ground_truth": use_ground_truth,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        str,
                        construct_type(
                            type_=str,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_model_versions(
        self, id: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> MlListModelVersionsResponse:
        """
        Get available versions of the model.

        Parameters
        ----------
        id : int

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MlListModelVersionsResponse
            List of available versions.

        Examples
        --------
        import asyncio

        from label_studio_sdk import AsyncLabelStudio

        client = AsyncLabelStudio(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.ml.list_model_versions(
                id=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/ml/{jsonable_encoder(id)}/versions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    MlListModelVersionsResponse,
                    construct_type(
                        type_=MlListModelVersionsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
