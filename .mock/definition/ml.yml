imports:
  root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    list:
      path: /api/ml/
      method: GET
      auth: true
      docs: |2-

            List all configured ML backends for a specific project by ID.
            Use the following cURL command:
            ```bash
            curl http://localhost:8000/api/ml?project={project_id} -H 'Authorization: Token abc123'
            
      source:
        openapi: openapi/openapi.yaml
      display-name: List ML backends
      request:
        name: MlListRequest
        query-parameters:
          project:
            type: optional<integer>
            docs: Project ID
      response:
        docs: ''
        type: list<root.MlBackend>
      examples:
        - response:
            body:
              - auth_method: NONE
                auto_update: true
                basic_auth_pass_is_set: basic_auth_pass_is_set
                basic_auth_user: basic_auth_user
                created_at: '2024-01-15T09:30:00Z'
                description: description
                error_message: error_message
                extra_params:
                  key: value
                id: 1
                is_interactive: true
                model_version: model_version
                project: 1
                readable_state: readable_state
                state: CO
                timeout: 1.1
                title: title
                updated_at: '2024-01-15T09:30:00Z'
                url: url
      audiences:
        - public
    create:
      path: /api/ml/
      method: POST
      auth: true
      docs: |2-

            Add an ML backend to a project using the Label Studio UI or by sending a POST request using the following cURL 
            command:
            ```bash
            curl -X POST -H 'Content-type: application/json' http://localhost:8000/api/ml -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9090", "project": {project_id}}' 
            
      source:
        openapi: openapi/openapi.yaml
      display-name: Add ML Backend
      request:
        name: MlCreateRequest
        body:
          properties:
            auth_method:
              type: optional<MlCreateRequestAuthMethod>
              docs: Auth method
            basic_auth_pass:
              type: optional<string>
              docs: Basic auth password
            basic_auth_user:
              type: optional<string>
              docs: Basic auth user
            description:
              type: optional<string>
              docs: Description
            extra_params:
              type: optional<map<string, unknown>>
              docs: Extra parameters
            is_interactive:
              type: optional<boolean>
              docs: Is interactive
            project:
              type: optional<integer>
              docs: Project ID
            timeout:
              type: optional<integer>
              docs: Response model timeout
            title:
              type: optional<string>
              docs: Title
            url:
              type: optional<string>
              docs: ML backend URL
        content-type: application/json
      response:
        docs: ''
        type: root.MlBackend
      examples:
        - request: {}
          response:
            body:
              auth_method: NONE
              auto_update: true
              basic_auth_pass_is_set: basic_auth_pass_is_set
              basic_auth_user: basic_auth_user
              created_at: '2024-01-15T09:30:00Z'
              description: description
              error_message: error_message
              extra_params:
                key: value
              id: 1
              is_interactive: true
              model_version: model_version
              project: 1
              readable_state: readable_state
              state: CO
              timeout: 1.1
              title: title
              updated_at: '2024-01-15T09:30:00Z'
              url: url
      audiences:
        - public
    get:
      path: /api/ml/{id}
      method: GET
      auth: true
      docs: |2-

            Get details about a specific ML backend connection by ID. For example, make a GET request using the
            following cURL command:
            ```bash
            curl http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'
            
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id: integer
      display-name: Get ML Backend
      response:
        docs: ''
        type: root.MlBackend
      examples:
        - path-parameters:
            id: 1
          response:
            body:
              auth_method: NONE
              auto_update: true
              basic_auth_pass_is_set: basic_auth_pass_is_set
              basic_auth_user: basic_auth_user
              created_at: '2024-01-15T09:30:00Z'
              description: description
              error_message: error_message
              extra_params:
                key: value
              id: 1
              is_interactive: true
              model_version: model_version
              project: 1
              readable_state: readable_state
              state: CO
              timeout: 1.1
              title: title
              updated_at: '2024-01-15T09:30:00Z'
              url: url
      audiences:
        - public
    delete:
      path: /api/ml/{id}
      method: DELETE
      auth: true
      docs: |2-

            Remove an existing ML backend connection by ID. For example, use the
            following cURL command:
            ```bash
            curl -X DELETE http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'
            
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id: integer
      display-name: Remove ML Backend
      examples:
        - path-parameters:
            id: 1
      audiences:
        - public
    update:
      path: /api/ml/{id}
      method: PATCH
      auth: true
      docs: |2-

            Update ML backend parameters using the Label Studio UI or by sending a PATCH request using the following cURL command:
            ```bash
            curl -X PATCH -H 'Content-type: application/json' http://localhost:8000/api/ml/{ml_backend_ID} -H 'Authorization: Token abc123'\
            --data '{"url": "http://localhost:9091"}' 
            
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id: integer
      display-name: Update ML Backend
      request:
        name: MlUpdateRequest
        body:
          properties:
            auth_method:
              type: optional<MlUpdateRequestAuthMethod>
              docs: Auth method
            basic_auth_pass:
              type: optional<string>
              docs: Basic auth password
            basic_auth_user:
              type: optional<string>
              docs: Basic auth user
            description:
              type: optional<string>
              docs: Description
            extra_params:
              type: optional<map<string, unknown>>
              docs: Extra parameters
            is_interactive:
              type: optional<boolean>
              docs: Is interactive
            project:
              type: optional<integer>
              docs: Project ID
            timeout:
              type: optional<integer>
              docs: Response model timeout
            title:
              type: optional<string>
              docs: Title
            url:
              type: optional<string>
              docs: ML backend URL
        content-type: application/json
      response:
        docs: ''
        type: root.MlBackend
      examples:
        - path-parameters:
            id: 1
          request: {}
          response:
            body:
              auth_method: NONE
              auto_update: true
              basic_auth_pass_is_set: basic_auth_pass_is_set
              basic_auth_user: basic_auth_user
              created_at: '2024-01-15T09:30:00Z'
              description: description
              error_message: error_message
              extra_params:
                key: value
              id: 1
              is_interactive: true
              model_version: model_version
              project: 1
              readable_state: readable_state
              state: CO
              timeout: 1.1
              title: title
              updated_at: '2024-01-15T09:30:00Z'
              url: url
      audiences:
        - public
    predict_interactive:
      path: /api/ml/{id}/interactive-annotating
      method: POST
      auth: true
      docs: |2-

                Send a request to the machine learning backend set up to be used for interactive preannotations to retrieve a
                predicted region based on annotator input. 
                See [set up machine learning](https://labelstud.io/guide/ml.html#Get-interactive-preannotations) for more.
                
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id:
          type: integer
          docs: A unique integer value identifying this ML backend.
      display-name: Request Interactive Annotation
      request:
        name: MlInteractiveAnnotatingRequestRequest
        body:
          properties:
            context: optional<unknown>
            task:
              type: integer
              docs: ID of task to annotate
        content-type: application/json
      examples:
        - path-parameters:
            id: 1
          request:
            task: 1
      audiences:
        - public
    predict_all_tasks:
      path: /api/ml/{id}/predict
      method: POST
      auth: true
      docs: >-
        Note: not available in the community edition of Label Studio. 


        Create predictions for all tasks using a specific ML backend so that you
        can set up an active learning strategy based on the confidence or
        uncertainty scores associated with the predictions. Creating predictions
        requires a Label Studio ML backend set up and configured for your
        project. 


        See [Set up machine learning](https://labelstud.io/guide/ml.html) for
        more details about a Label Studio ML backend. 


        Reference the ML backend ID in the path of this API call. Get the ML
        backend ID by [listing the ML backends for a
        project](https://labelstud.io/api/#operation/api_ml_list).
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id:
          type: integer
          docs: A unique integer value identifying this ML backend.
      display-name: Create predictions for all tasks
      request:
        name: MlPredictAllTasksRequest
        query-parameters:
          batch_size:
            type: optional<integer>
            docs: >-
              Computed number of tasks without predictions that the ML backend
              needs to predict.
      examples:
        - path-parameters:
            id: 1
      audiences:
        - public
    test_predict:
      path: /api/ml/{id}/predict/test
      method: POST
      auth: true
      docs: |2-

                After you add an ML backend, call this API with the ML backend ID to run a test prediction on specific task data               
                
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id:
          type: integer
          docs: A unique integer value identifying this ML backend.
      display-name: Test prediction
      request:
        name: MlBackendRequest
        body:
          properties:
            auth_method: optional<root.AuthMethodEnum>
            auto_update:
              type: optional<boolean>
              docs: >-
                If false, model version is set by the user, if true - getting
                latest version from backend.
            basic_auth_pass: optional<string>
            basic_auth_user:
              type: optional<string>
              docs: HTTP Basic Auth user
            description:
              type: optional<string>
              docs: Description for the machine learning backend
            error_message:
              type: optional<string>
              docs: Error message in error state
            extra_params: optional<unknown>
            is_interactive:
              type: optional<boolean>
              docs: >-
                Used to interactively annotate tasks. If true, model returns one
                list with results
            model_version:
              type: optional<string>
              docs: >-
                Current model version associated with this machine learning
                backend
            project: integer
            state: optional<root.StateEnum>
            timeout:
              type: optional<double>
              docs: Response model timeout
            title:
              type: optional<string>
              docs: Name of the machine learning backend
            url:
              type: string
              docs: URL for the machine learning model server
              validation:
                minLength: 1
        content-type: application/json
      errors:
        - root.InternalServerError
      examples:
        - path-parameters:
            id: 1
          request:
            project: 1
            url: url
      audiences:
        - internal
    train:
      path: /api/ml/{id}/train
      method: POST
      auth: true
      docs: |2-

                After you add an ML backend, call this API with the ML backend ID to start training with 
                already-labeled tasks. 
                
                Get the ML backend ID by [listing the ML backends for a project](https://labelstud.io/api/#operation/api_ml_list).
                
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id:
          type: integer
          docs: A unique integer value identifying this ML backend.
      display-name: Train
      request:
        name: MlTrainRequest
        body:
          properties:
            use_ground_truth:
              type: optional<boolean>
              docs: Whether to include ground truth annotations in training
        content-type: application/json
      errors:
        - root.InternalServerError
      examples:
        - path-parameters:
            id: 1
          request: {}
      audiences:
        - public
    list_model_versions:
      path: /api/ml/{id}/versions
      method: GET
      auth: true
      docs: Get available versions of the model.
      source:
        openapi: openapi/openapi.yaml
      path-parameters:
        id: integer
      display-name: Get model versions
      response:
        docs: List of available versions.
        type: MlListModelVersionsResponse
      examples:
        - path-parameters:
            id: 1
          response:
            body:
              message: message
              versions:
                - versions
      audiences:
        - public
  source:
    openapi: openapi/openapi.yaml
types:
  MlCreateRequestAuthMethod:
    enum:
      - NONE
      - BASIC_AUTH
    docs: Auth method
    inline: true
    source:
      openapi: openapi/openapi.yaml
  MlUpdateRequestAuthMethod:
    enum:
      - NONE
      - BASIC_AUTH
    docs: Auth method
    inline: true
    source:
      openapi: openapi/openapi.yaml
  MlListModelVersionsResponse:
    properties:
      message: optional<string>
      versions: optional<list<string>>
    source:
      openapi: openapi/openapi.yaml
