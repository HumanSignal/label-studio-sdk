{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak Supervision with Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform weak supervision with Label Studio, using noisy labels on a large amount of training data to automatically build a useful training dataset for your supervised learning model. \n",
    "\n",
    "In this example, use the [Label Studio SDK](https://labelstud.io/sdk/index.html) to write a Python script that adds noisy labels to tasks, then adds those tasks to Label Studio for review and correction in a supervised learning setting.\n",
    "\n",
    "**Note:** This code utilizes functions from an older version of the Label Studio SDK (v0.0.34).\n",
    "The newer versions v1.0 and above still support the functionalities of the old version, but you will need to specify\n",
    "[`label_studio_sdk._legacy`](../../README.md) in your script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Label Studio\n",
    "\n",
    "Connect to the API for Label Studio Community, Enterprise, or Teams edition. Use the Client module of the Label Studio SDK and check the connection is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "\n",
    "ls = LabelStudio(base_url=os.getenv('LABEL_STUDIO_URL', 'http://localhost:8080'), api_key=os.getenv('LABEL_STUDIO_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project\n",
    "\n",
    "Create a simple text classification project to perform [sentiment analysis](https://labelstud.io/templates/sentiment_analysis.html) to identify the sentiment expressed by a passage of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = ls.projects.create(\n",
    "    title='Weak Supervision example with SDK',\n",
    "    label_config='''\n",
    "    <View>\n",
    "    <Text name=\"text\" value=\"$text\"/>\n",
    "    <View style=\"box-shadow: 2px 2px 5px #999; padding: 20px; margin-top: 2em; border-radius: 5px;\">\n",
    "        <Header value=\"Choose text sentiment\"/>\n",
    "        <Choices name=\"sentiment\" toName=\"text\" choice=\"single\" showInLine=\"true\">\n",
    "            <Choice value=\"Positive\"/>\n",
    "            <Choice value=\"Negative\"/>\n",
    "            <Choice value=\"Neutral\"/>\n",
    "        </Choices>\n",
    "    </View>\n",
    "    </View>\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tasks\n",
    "\n",
    "Import small text samples into Label Studio, and retrieve their task IDs. This examples uses a small subset of tasks from the available Amazon Review dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "p1 = os.path.join('data', 'amazon_cells_labelled.tsv')\n",
    "p2 = os.path.join('weak_supervision', 'data', 'amazon_cells_labelled.tsv')\n",
    "csv_path = p1 if os.path.exists(p1) else p2\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"Error: Data file not found at {p1} or {p2}.\")\n",
    "    tasks = []\n",
    "else:\n",
    "    tasks = pd.read_csv(csv_path, sep='\\t').to_dict('records')\n",
    "    # Bulk import tasks via v2\n",
    "    _ = ls.projects.import_tasks(id=project.id, request=tasks)\n",
    "    # Fetch ids afterwards if needed\n",
    "    ids = [t.id for t in ls.tasks.list(project=project.id, fields='task_only')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create noisy predictions\n",
    "\n",
    "Perform programmatic labeling to create weakly supervised annotations for the text samples. Our labeling operations, or in shorthand, **LabelOps**, are noisy programmatic labelers that reflect subject matter experts' domain knowledge in a simple pattern-to-class mapping form. In this example, assigning a sentiment class based on specific key words in the Amazon review. In more complex scenarios, the noisy labeling could be performed on the output of a learned classifier using confidence scores, crowdsourced labels, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "\n",
    "# Noisy programmatic labelers\n",
    "label_ops = {\n",
    "    r'.*\\b(good|excellent|great|cool)': 'Positive',\n",
    "    r'.*\\bi\\s+like': 'Positive',\n",
    "    r'.*\\bnot': 'Negative',\n",
    "    r'.*\\bdisappointed': 'Negative',\n",
    "    r'.*\\bjunk': 'Negative'\n",
    "}\n",
    "\n",
    "# Pre-annotations in Label Studio JSON format (v2)\n",
    "for label_regex, label in label_ops.items():\n",
    "    model_version = label_regex\n",
    "    for t in ls.tasks.list(project=project.id, fields='task_only'):\n",
    "        text = t.data.get('text', '').lower()\n",
    "        if re.match(label_regex, text):\n",
    "            ls.predictions.create(\n",
    "                task=t.id,\n",
    "                result=[{\n",
    "                    'from_name': 'sentiment',\n",
    "                    'to_name': 'text',\n",
    "                    'type': 'choices',\n",
    "                    'value': {\n",
    "                        'choices': [label]\n",
    "                    }\n",
    "                }],\n",
    "                score=float(random.random()),\n",
    "                model_version=model_version\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Quality metrics\n",
    "\n",
    "Some quality metrics endpoints are Enterprise-only or not exposed in SDK v2. Skipping metrics in this OSS-compatible notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped: Enterprise-only or not exposed metrics in SDK v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create annotations from specific model versions\n",
    "\n",
    "Based on quality metrics from previous steps, select a subset of high-performing programmatic labelers to use, then combine the relevant predictions into annotations for the relevant tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Skipping conversion of predictions to annotations (Enterprise-only or custom implementation needed).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After performing programmatic noisy labeling on a dataset, you can evaluate the quality of the predictions programmatically. Then, using the Label Studio SDK, you can transform the best quality predictions into annotations to train a weakly supervised model.\n",
    "\n",
    "If you want, you can also take the most confusing items in the dataset for the programmatic labelers and [import pre-annotations into Label Studio](https://github.com/heartexlabs/label-studio-sdk/blob/master/examples/Import%20preannotations.ipynb) for human-in-the-loop annotator review and correction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
